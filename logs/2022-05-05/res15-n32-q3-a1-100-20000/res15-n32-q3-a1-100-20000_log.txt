Date: 2022-05-06 04:40:08.317063 

Model name: res15
Dataset: n32-q3-a1-100-20000
Input shape: (32, 100)
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 45, 32, 100]             405
            Conv2d-2          [-1, 45, 32, 100]          18,225
       BatchNorm2d-3          [-1, 45, 32, 100]               0
            Conv2d-4          [-1, 45, 32, 100]          18,225
       BatchNorm2d-5          [-1, 45, 32, 100]               0
            Conv2d-6          [-1, 45, 32, 100]          18,225
       BatchNorm2d-7          [-1, 45, 32, 100]               0
            Conv2d-8          [-1, 45, 32, 100]          18,225
       BatchNorm2d-9          [-1, 45, 32, 100]               0
           Conv2d-10          [-1, 45, 32, 100]          18,225
      BatchNorm2d-11          [-1, 45, 32, 100]               0
           Conv2d-12          [-1, 45, 32, 100]          18,225
      BatchNorm2d-13          [-1, 45, 32, 100]               0
           Conv2d-14          [-1, 45, 32, 100]          18,225
      BatchNorm2d-15          [-1, 45, 32, 100]               0
           Conv2d-16          [-1, 45, 32, 100]          18,225
      BatchNorm2d-17          [-1, 45, 32, 100]               0
           Conv2d-18          [-1, 45, 32, 100]          18,225
      BatchNorm2d-19          [-1, 45, 32, 100]               0
           Conv2d-20          [-1, 45, 32, 100]          18,225
      BatchNorm2d-21          [-1, 45, 32, 100]               0
           Conv2d-22          [-1, 45, 32, 100]          18,225
      BatchNorm2d-23          [-1, 45, 32, 100]               0
           Conv2d-24          [-1, 45, 32, 100]          18,225
      BatchNorm2d-25          [-1, 45, 32, 100]               0
           Conv2d-26          [-1, 45, 32, 100]          18,225
      BatchNorm2d-27          [-1, 45, 32, 100]               0
           Linear-28                   [-1, 10]             460
================================================================
Total params: 237,790
Trainable params: 237,790
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 29.66
Params size (MB): 0.91
Estimated Total Size (MB): 30.58
----------------------------------------------------------------
traning sample:18945
validation sample:2369
testing sample:2368

Using gpu: Tesla K80
Training epoches: 20
Training batches: 296

Epoch: 1
train step #0/296 acc: 0.140625, loss: 2.290279
train step #50/296 acc: 0.640625, loss: 1.288089
train step #100/296 acc: 0.625000, loss: 1.042977
train step #150/296 acc: 0.734375, loss: 0.753535
train step #200/296 acc: 0.859375, loss: 0.540345
train step #250/296 acc: 0.875000, loss: 0.417589
Validation acc: 0.406661, loss: 1.825543
saving best model ...
Test acc: 0.402449, loss: 1.843570
Cost time:528.886461s

Epoch: 2
train step #0/296 acc: 0.921875, loss: 0.392473
train step #50/296 acc: 0.890625, loss: 0.320944
train step #100/296 acc: 0.875000, loss: 0.375672
train step #150/296 acc: 0.921875, loss: 0.285024
train step #200/296 acc: 0.921875, loss: 0.282504
train step #250/296 acc: 0.953125, loss: 0.199101
Validation acc: 0.887336, loss: 0.384336
saving best model ...
Test acc: 0.890625, loss: 0.358975
Cost time:156.975933s

Epoch: 3
train step #0/296 acc: 0.953125, loss: 0.132702
train step #50/296 acc: 0.953125, loss: 0.152055
train step #100/296 acc: 0.937500, loss: 0.226019
train step #150/296 acc: 0.921875, loss: 0.240740
train step #200/296 acc: 0.953125, loss: 0.205010
train step #250/296 acc: 0.953125, loss: 0.155056
Validation acc: 0.890625, loss: 0.358707
saving best model ...
Test acc: 0.891470, loss: 0.338355
Cost time:157.640371s

Epoch: 4
train step #0/296 acc: 1.000000, loss: 0.048502
train step #50/296 acc: 0.968750, loss: 0.136053
train step #100/296 acc: 0.937500, loss: 0.204088
train step #150/296 acc: 0.953125, loss: 0.153666
train step #200/296 acc: 0.968750, loss: 0.124463
train step #250/296 acc: 0.953125, loss: 0.139411
Validation acc: 0.918174, loss: 0.263938
saving best model ...
Test acc: 0.915118, loss: 0.259930
Cost time:156.663933s

Epoch: 5
train step #0/296 acc: 0.984375, loss: 0.045757
train step #50/296 acc: 0.968750, loss: 0.097759
train step #100/296 acc: 0.968750, loss: 0.163736
train step #150/296 acc: 0.953125, loss: 0.163797
train step #200/296 acc: 0.984375, loss: 0.117201
train step #250/296 acc: 0.953125, loss: 0.143352
Validation acc: 0.929688, loss: 0.198330
saving best model ...
Test acc: 0.939189, loss: 0.185454
Cost time:156.336580s

Epoch: 6
train step #0/296 acc: 1.000000, loss: 0.033449
train step #50/296 acc: 0.984375, loss: 0.062960
train step #100/296 acc: 0.968750, loss: 0.111978
train step #150/296 acc: 0.984375, loss: 0.072611
train step #200/296 acc: 0.953125, loss: 0.122865
train step #250/296 acc: 0.953125, loss: 0.142041
Validation acc: 0.939967, loss: 0.182198
saving best model ...
Test acc: 0.950591, loss: 0.166449
Cost time:156.856982s

Epoch: 7
train step #0/296 acc: 1.000000, loss: 0.038458
train step #50/296 acc: 0.984375, loss: 0.119622
train step #100/296 acc: 0.968750, loss: 0.113933
train step #150/296 acc: 0.937500, loss: 0.103321
train step #200/296 acc: 0.968750, loss: 0.128856
train step #250/296 acc: 0.953125, loss: 0.147006
Validation acc: 0.946546, loss: 0.164351
saving best model ...
Test acc: 0.957348, loss: 0.144972
Cost time:157.175985s

Epoch: 8
train step #0/296 acc: 0.984375, loss: 0.045126
train step #50/296 acc: 0.984375, loss: 0.073100
train step #100/296 acc: 0.968750, loss: 0.094827
train step #150/296 acc: 0.984375, loss: 0.061317
train step #200/296 acc: 0.968750, loss: 0.122082
train step #250/296 acc: 0.953125, loss: 0.112004
Validation acc: 0.952303, loss: 0.155550
saving best model ...
Test acc: 0.961571, loss: 0.135842
Cost time:156.867094s

Epoch: 9
train step #0/296 acc: 0.968750, loss: 0.038561
train step #50/296 acc: 0.984375, loss: 0.049116
train step #100/296 acc: 0.968750, loss: 0.110819
train step #150/296 acc: 0.984375, loss: 0.071836
train step #200/296 acc: 0.984375, loss: 0.100236
train step #250/296 acc: 0.953125, loss: 0.121095
Validation acc: 0.948191, loss: 0.163713
Test acc: 0.953970, loss: 0.143732
Cost time:156.262878s

Epoch: 10
train step #0/296 acc: 1.000000, loss: 0.020468
train step #50/296 acc: 0.984375, loss: 0.046836
train step #100/296 acc: 0.968750, loss: 0.069668
train step #150/296 acc: 0.968750, loss: 0.083628
train step #200/296 acc: 0.968750, loss: 0.107874
train step #250/296 acc: 0.968750, loss: 0.088922
Validation acc: 0.932155, loss: 0.222579
Test acc: 0.939189, loss: 0.213302
Cost time:157.133899s

Epoch: 11
train step #0/296 acc: 1.000000, loss: 0.021465
train step #50/296 acc: 0.984375, loss: 0.064860
train step #100/296 acc: 0.984375, loss: 0.088620
train step #150/296 acc: 0.984375, loss: 0.072540
train step #200/296 acc: 0.968750, loss: 0.111415
train step #250/296 acc: 0.937500, loss: 0.141775
Validation acc: 0.954770, loss: 0.144798
saving best model ...
Test acc: 0.962838, loss: 0.125624
Cost time:156.769538s

Epoch: 12
train step #0/296 acc: 0.984375, loss: 0.031021
train step #50/296 acc: 0.984375, loss: 0.056722
train step #100/296 acc: 0.968750, loss: 0.066015
train step #150/296 acc: 0.968750, loss: 0.055427
train step #200/296 acc: 0.968750, loss: 0.118993
train step #250/296 acc: 0.953125, loss: 0.117014
Validation acc: 0.956003, loss: 0.140159
saving best model ...
Test acc: 0.960726, loss: 0.126760
Cost time:156.131070s

Epoch: 13
train step #0/296 acc: 1.000000, loss: 0.013628
train step #50/296 acc: 0.984375, loss: 0.050350
train step #100/296 acc: 0.968750, loss: 0.090251
train step #150/296 acc: 1.000000, loss: 0.021415
train step #200/296 acc: 0.984375, loss: 0.096359
train step #250/296 acc: 0.968750, loss: 0.099960
Validation acc: 0.949424, loss: 0.168710
Test acc: 0.950169, loss: 0.164811
Cost time:157.241786s

Epoch: 14
train step #0/296 acc: 1.000000, loss: 0.024957
train step #50/296 acc: 0.984375, loss: 0.032478
train step #100/296 acc: 0.968750, loss: 0.077765
train step #150/296 acc: 0.984375, loss: 0.034739
train step #200/296 acc: 0.953125, loss: 0.120773
train step #250/296 acc: 0.953125, loss: 0.095592
Validation acc: 0.955592, loss: 0.137637
Test acc: 0.959037, loss: 0.136624
Cost time:156.979051s

Epoch: 15
train step #0/296 acc: 1.000000, loss: 0.010166
train step #50/296 acc: 0.984375, loss: 0.042707
train step #100/296 acc: 0.968750, loss: 0.132764
train step #150/296 acc: 1.000000, loss: 0.010313
train step #200/296 acc: 0.984375, loss: 0.092500
train step #250/296 acc: 0.968750, loss: 0.100436
Validation acc: 0.953947, loss: 0.154246
Test acc: 0.956926, loss: 0.139439
Cost time:156.538623s

Epoch: 16
train step #0/296 acc: 1.000000, loss: 0.009097
train step #50/296 acc: 1.000000, loss: 0.006152
train step #100/296 acc: 1.000000, loss: 0.017166
train step #150/296 acc: 1.000000, loss: 0.012840
train step #200/296 acc: 0.968750, loss: 0.109221
train step #250/296 acc: 0.953125, loss: 0.101838
Validation acc: 0.952303, loss: 0.156319
Test acc: 0.957770, loss: 0.142430
Cost time:157.022564s

Epoch: 17
train step #0/296 acc: 0.984375, loss: 0.027827
train step #50/296 acc: 0.984375, loss: 0.037689
train step #100/296 acc: 1.000000, loss: 0.022372
train step #150/296 acc: 1.000000, loss: 0.030141
train step #200/296 acc: 0.984375, loss: 0.058787
train step #250/296 acc: 0.953125, loss: 0.100594
Validation acc: 0.938322, loss: 0.204138
Test acc: 0.945524, loss: 0.196562
Cost time:157.219522s

Epoch: 18
train step #0/296 acc: 1.000000, loss: 0.012801
train step #50/296 acc: 0.984375, loss: 0.025935
train step #100/296 acc: 0.984375, loss: 0.047699
train step #150/296 acc: 1.000000, loss: 0.005052
train step #200/296 acc: 0.968750, loss: 0.102544
train step #250/296 acc: 0.968750, loss: 0.079822
Validation acc: 0.952714, loss: 0.159113
Test acc: 0.958615, loss: 0.133318
Cost time:157.356565s

Epoch: 19
train step #0/296 acc: 1.000000, loss: 0.025505
train step #50/296 acc: 1.000000, loss: 0.014589
train step #100/296 acc: 0.984375, loss: 0.028424
train step #150/296 acc: 1.000000, loss: 0.011523
train step #200/296 acc: 0.968750, loss: 0.080735
train step #250/296 acc: 0.968750, loss: 0.071347
Validation acc: 0.948602, loss: 0.175881
Test acc: 0.952280, loss: 0.163019
Cost time:156.034757s

Epoch: 20
train step #0/296 acc: 0.984375, loss: 0.044602
train step #50/296 acc: 1.000000, loss: 0.007939
train step #100/296 acc: 1.000000, loss: 0.022062
train step #150/296 acc: 1.000000, loss: 0.010718
train step #200/296 acc: 0.953125, loss: 0.097138
train step #250/296 acc: 0.968750, loss: 0.070284
Validation acc: 0.953536, loss: 0.152248
Test acc: 0.959459, loss: 0.139291
Cost time:156.797680s

Test acc: 0.960726, loss: 0.126760
Best validation acc:0.956003
