Date: 2022-05-05 20:47:26.703590 

Model name: res15
Dataset: n32-q3-a1-100-4000
Input shape: (32, 100)
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 45, 32, 100]             405
            Conv2d-2          [-1, 45, 32, 100]          18,225
       BatchNorm2d-3          [-1, 45, 32, 100]               0
            Conv2d-4          [-1, 45, 32, 100]          18,225
       BatchNorm2d-5          [-1, 45, 32, 100]               0
            Conv2d-6          [-1, 45, 32, 100]          18,225
       BatchNorm2d-7          [-1, 45, 32, 100]               0
            Conv2d-8          [-1, 45, 32, 100]          18,225
       BatchNorm2d-9          [-1, 45, 32, 100]               0
           Conv2d-10          [-1, 45, 32, 100]          18,225
      BatchNorm2d-11          [-1, 45, 32, 100]               0
           Conv2d-12          [-1, 45, 32, 100]          18,225
      BatchNorm2d-13          [-1, 45, 32, 100]               0
           Conv2d-14          [-1, 45, 32, 100]          18,225
      BatchNorm2d-15          [-1, 45, 32, 100]               0
           Conv2d-16          [-1, 45, 32, 100]          18,225
      BatchNorm2d-17          [-1, 45, 32, 100]               0
           Conv2d-18          [-1, 45, 32, 100]          18,225
      BatchNorm2d-19          [-1, 45, 32, 100]               0
           Conv2d-20          [-1, 45, 32, 100]          18,225
      BatchNorm2d-21          [-1, 45, 32, 100]               0
           Conv2d-22          [-1, 45, 32, 100]          18,225
      BatchNorm2d-23          [-1, 45, 32, 100]               0
           Conv2d-24          [-1, 45, 32, 100]          18,225
      BatchNorm2d-25          [-1, 45, 32, 100]               0
           Conv2d-26          [-1, 45, 32, 100]          18,225
      BatchNorm2d-27          [-1, 45, 32, 100]               0
           Linear-28                   [-1, 10]             460
================================================================
Total params: 237,790
Trainable params: 237,790
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 29.66
Params size (MB): 0.91
Estimated Total Size (MB): 30.58
----------------------------------------------------------------
traning sample:18945
validation sample:2369
testing sample:2368

Using gpu: Tesla K80
Training epoches: 20
Training batches: 296

Epoch: 1
train step #0/296 acc: 0.078125, loss: 2.294879
train step #50/296 acc: 0.718750, loss: 1.139192
train step #100/296 acc: 0.875000, loss: 0.671228
train step #150/296 acc: 0.828125, loss: 0.583992
train step #200/296 acc: 0.937500, loss: 0.380146
train step #250/296 acc: 0.968750, loss: 0.247639
Validation acc: 0.446135, loss: 2.134602
saving best model ...
Test acc: 0.426943, loss: 2.221037
Cost time:580.676841s

Epoch: 2
train step #0/296 acc: 0.937500, loss: 0.319458
train step #50/296 acc: 0.953125, loss: 0.204615
train step #100/296 acc: 0.906250, loss: 0.341387
train step #150/296 acc: 0.921875, loss: 0.295866
train step #200/296 acc: 0.937500, loss: 0.217444
train step #250/296 acc: 0.968750, loss: 0.136279
Validation acc: 0.926398, loss: 0.229175
saving best model ...
Test acc: 0.923986, loss: 0.250259
Cost time:156.513657s

Epoch: 3
train step #0/296 acc: 0.968750, loss: 0.127013
train step #50/296 acc: 0.968750, loss: 0.156211
train step #100/296 acc: 0.890625, loss: 0.312263
train step #150/296 acc: 0.921875, loss: 0.186084
train step #200/296 acc: 0.984375, loss: 0.081663
train step #250/296 acc: 0.984375, loss: 0.086191
Validation acc: 0.937911, loss: 0.204731
saving best model ...
Test acc: 0.930743, loss: 0.220670
Cost time:157.771485s

Epoch: 4
train step #0/296 acc: 0.968750, loss: 0.101166
train step #50/296 acc: 0.953125, loss: 0.094201
train step #100/296 acc: 0.921875, loss: 0.281111
train step #150/296 acc: 0.937500, loss: 0.160083
train step #200/296 acc: 0.984375, loss: 0.085284
train step #250/296 acc: 0.984375, loss: 0.059734
Validation acc: 0.927220, loss: 0.240691
Test acc: 0.916807, loss: 0.274077
Cost time:157.165834s

Epoch: 5
train step #0/296 acc: 0.984375, loss: 0.058794
train step #50/296 acc: 0.968750, loss: 0.069201
train step #100/296 acc: 0.937500, loss: 0.197020
train step #150/296 acc: 0.968750, loss: 0.099745
train step #200/296 acc: 1.000000, loss: 0.022914
train step #250/296 acc: 0.984375, loss: 0.062702
Validation acc: 0.950658, loss: 0.156430
saving best model ...
Test acc: 0.938767, loss: 0.179559
Cost time:156.898104s

Epoch: 6
train step #0/296 acc: 1.000000, loss: 0.032861
train step #50/296 acc: 0.968750, loss: 0.085570
train step #100/296 acc: 0.953125, loss: 0.162354
train step #150/296 acc: 0.968750, loss: 0.079126
train step #200/296 acc: 1.000000, loss: 0.017901
train step #250/296 acc: 0.984375, loss: 0.055445
Validation acc: 0.944490, loss: 0.181608
Test acc: 0.937078, loss: 0.192381
Cost time:157.930828s

Epoch: 7
train step #0/296 acc: 1.000000, loss: 0.020082
train step #50/296 acc: 0.968750, loss: 0.076126
train step #100/296 acc: 0.953125, loss: 0.171478
train step #150/296 acc: 0.968750, loss: 0.075902
train step #200/296 acc: 1.000000, loss: 0.023480
train step #250/296 acc: 0.984375, loss: 0.056843
Validation acc: 0.958059, loss: 0.126319
saving best model ...
Test acc: 0.955659, loss: 0.138286
Cost time:157.107823s

Epoch: 8
train step #0/296 acc: 0.984375, loss: 0.038443
train step #50/296 acc: 1.000000, loss: 0.031640
train step #100/296 acc: 0.937500, loss: 0.129070
train step #150/296 acc: 0.968750, loss: 0.076527
train step #200/296 acc: 1.000000, loss: 0.021721
train step #250/296 acc: 0.984375, loss: 0.044041
Validation acc: 0.956414, loss: 0.132440
Test acc: 0.948902, loss: 0.158751
Cost time:156.598650s

Epoch: 9
train step #0/296 acc: 1.000000, loss: 0.020825
train step #50/296 acc: 1.000000, loss: 0.027859
train step #100/296 acc: 0.968750, loss: 0.086316
train step #150/296 acc: 0.984375, loss: 0.049642
train step #200/296 acc: 1.000000, loss: 0.034133
train step #250/296 acc: 0.984375, loss: 0.047316
Validation acc: 0.953947, loss: 0.136453
Test acc: 0.953970, loss: 0.143594
Cost time:157.224791s

Epoch: 10
train step #0/296 acc: 1.000000, loss: 0.033617
train step #50/296 acc: 0.984375, loss: 0.036529
train step #100/296 acc: 0.953125, loss: 0.119865
train step #150/296 acc: 0.984375, loss: 0.050320
train step #200/296 acc: 1.000000, loss: 0.013760
train step #250/296 acc: 0.968750, loss: 0.060856
Validation acc: 0.963405, loss: 0.120515
saving best model ...
Test acc: 0.954814, loss: 0.145543
Cost time:157.859614s

Epoch: 11
train step #0/296 acc: 1.000000, loss: 0.010705
train step #50/296 acc: 0.984375, loss: 0.067703
train step #100/296 acc: 0.968750, loss: 0.085940
train step #150/296 acc: 0.984375, loss: 0.058141
train step #200/296 acc: 1.000000, loss: 0.008756
train step #250/296 acc: 0.984375, loss: 0.046481
Validation acc: 0.943257, loss: 0.195182
Test acc: 0.944257, loss: 0.176018
Cost time:157.087341s

Epoch: 12
train step #0/296 acc: 1.000000, loss: 0.013795
train step #50/296 acc: 1.000000, loss: 0.007954
train step #100/296 acc: 0.953125, loss: 0.134052
train step #150/296 acc: 0.984375, loss: 0.038219
train step #200/296 acc: 1.000000, loss: 0.012949
train step #250/296 acc: 0.968750, loss: 0.061957
Validation acc: 0.951069, loss: 0.158239
Test acc: 0.946368, loss: 0.156627
Cost time:156.479555s

Epoch: 13
train step #0/296 acc: 0.984375, loss: 0.033274
train step #50/296 acc: 1.000000, loss: 0.016029
train step #100/296 acc: 0.984375, loss: 0.069456
train step #150/296 acc: 0.984375, loss: 0.056119
train step #200/296 acc: 1.000000, loss: 0.005763
train step #250/296 acc: 0.984375, loss: 0.042591
Validation acc: 0.959704, loss: 0.110716
Test acc: 0.953970, loss: 0.143287
Cost time:156.923329s

Epoch: 14
train step #0/296 acc: 1.000000, loss: 0.015066
train step #50/296 acc: 1.000000, loss: 0.010340
train step #100/296 acc: 0.968750, loss: 0.069764
train step #150/296 acc: 0.984375, loss: 0.049690
train step #200/296 acc: 0.984375, loss: 0.016669
train step #250/296 acc: 0.984375, loss: 0.038989
Validation acc: 0.962582, loss: 0.121007
Test acc: 0.951858, loss: 0.149395
Cost time:158.313244s

Epoch: 15
train step #0/296 acc: 1.000000, loss: 0.014170
train step #50/296 acc: 1.000000, loss: 0.013451
train step #100/296 acc: 1.000000, loss: 0.045913
train step #150/296 acc: 0.984375, loss: 0.050064
train step #200/296 acc: 1.000000, loss: 0.006391
train step #250/296 acc: 0.984375, loss: 0.049867
Validation acc: 0.951069, loss: 0.157526
Test acc: 0.947635, loss: 0.170228
Cost time:156.753439s

Epoch: 16
train step #0/296 acc: 0.984375, loss: 0.064584
train step #50/296 acc: 1.000000, loss: 0.011705
train step #100/296 acc: 0.968750, loss: 0.109377
train step #150/296 acc: 0.968750, loss: 0.078277
train step #200/296 acc: 1.000000, loss: 0.008434
train step #250/296 acc: 0.984375, loss: 0.040981
Validation acc: 0.962582, loss: 0.117212
Test acc: 0.963682, loss: 0.121496
Cost time:157.111160s

Epoch: 17
train step #0/296 acc: 0.984375, loss: 0.017250
train step #50/296 acc: 1.000000, loss: 0.017161
train step #100/296 acc: 1.000000, loss: 0.037691
train step #150/296 acc: 0.984375, loss: 0.059269
train step #200/296 acc: 1.000000, loss: 0.004112
train step #250/296 acc: 0.984375, loss: 0.034476
Validation acc: 0.962171, loss: 0.129509
Test acc: 0.958615, loss: 0.144748
Cost time:157.860135s

Epoch: 18
train step #0/296 acc: 0.984375, loss: 0.018812
train step #50/296 acc: 1.000000, loss: 0.002095
train step #100/296 acc: 0.984375, loss: 0.045294
train step #150/296 acc: 0.984375, loss: 0.044486
train step #200/296 acc: 1.000000, loss: 0.005425
train step #250/296 acc: 0.984375, loss: 0.031546
Validation acc: 0.956003, loss: 0.169708
Test acc: 0.949747, loss: 0.167587
Cost time:157.211286s

Epoch: 19
train step #0/296 acc: 0.984375, loss: 0.105766
train step #50/296 acc: 0.984375, loss: 0.019151
train step #100/296 acc: 0.984375, loss: 0.048623
train step #150/296 acc: 0.984375, loss: 0.046081
train step #200/296 acc: 1.000000, loss: 0.002343
train step #250/296 acc: 0.984375, loss: 0.047399
Validation acc: 0.954359, loss: 0.151064
Test acc: 0.950591, loss: 0.166507
Cost time:157.151798s

Epoch: 20
train step #0/296 acc: 1.000000, loss: 0.008829
train step #50/296 acc: 0.968750, loss: 0.112696
train step #100/296 acc: 1.000000, loss: 0.028930
train step #150/296 acc: 0.968750, loss: 0.053732
train step #200/296 acc: 0.984375, loss: 0.051897
train step #250/296 acc: 0.984375, loss: 0.041254
Validation acc: 0.959293, loss: 0.136663
Test acc: 0.957770, loss: 0.138066
Cost time:156.932613s

Test acc: 0.954814, loss: 0.145543
Best validation acc:0.963405
