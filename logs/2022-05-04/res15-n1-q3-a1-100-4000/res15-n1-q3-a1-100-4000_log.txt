Date: 2022-05-04 01:16:36.636923 

Model name: res15
Dataset: n1-q3-a1-100-4000
Input shape: (5, 104)
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 45, 5, 104]             405
            Conv2d-2           [-1, 45, 5, 104]          18,225
       BatchNorm2d-3           [-1, 45, 5, 104]               0
            Conv2d-4           [-1, 45, 5, 104]          18,225
       BatchNorm2d-5           [-1, 45, 5, 104]               0
            Conv2d-6           [-1, 45, 5, 104]          18,225
       BatchNorm2d-7           [-1, 45, 5, 104]               0
            Conv2d-8           [-1, 45, 5, 104]          18,225
       BatchNorm2d-9           [-1, 45, 5, 104]               0
           Conv2d-10           [-1, 45, 5, 104]          18,225
      BatchNorm2d-11           [-1, 45, 5, 104]               0
           Conv2d-12           [-1, 45, 5, 104]          18,225
      BatchNorm2d-13           [-1, 45, 5, 104]               0
           Conv2d-14           [-1, 45, 5, 104]          18,225
      BatchNorm2d-15           [-1, 45, 5, 104]               0
           Conv2d-16           [-1, 45, 5, 104]          18,225
      BatchNorm2d-17           [-1, 45, 5, 104]               0
           Conv2d-18           [-1, 45, 5, 104]          18,225
      BatchNorm2d-19           [-1, 45, 5, 104]               0
           Conv2d-20           [-1, 45, 5, 104]          18,225
      BatchNorm2d-21           [-1, 45, 5, 104]               0
           Conv2d-22           [-1, 45, 5, 104]          18,225
      BatchNorm2d-23           [-1, 45, 5, 104]               0
           Conv2d-24           [-1, 45, 5, 104]          18,225
      BatchNorm2d-25           [-1, 45, 5, 104]               0
           Conv2d-26           [-1, 45, 5, 104]          18,225
      BatchNorm2d-27           [-1, 45, 5, 104]               0
           Linear-28                   [-1, 10]             460
================================================================
Total params: 237,790
Trainable params: 237,790
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 4.82
Params size (MB): 0.91
Estimated Total Size (MB): 5.73
----------------------------------------------------------------
traning sample:18945
validation sample:2369
testing sample:2368

Using gpu: Tesla K80
Training epoches: 20
Training batches: 296

Epoch: 1
train step #0/296 acc: 0.093750, loss: 2.277104
train step #50/296 acc: 0.343750, loss: 1.787299
train step #100/296 acc: 0.515625, loss: 1.461542
train step #150/296 acc: 0.609375, loss: 1.199270
train step #200/296 acc: 0.453125, loss: 1.507502
train step #250/296 acc: 0.578125, loss: 1.168516
Validation acc: 0.598684, loss: 1.141879
saving best model ...
Test acc: 0.630490, loss: 1.087608
Cost time:38.796963s

Epoch: 2
train step #0/296 acc: 0.562500, loss: 1.177720
train step #50/296 acc: 0.625000, loss: 0.958729
train step #100/296 acc: 0.718750, loss: 1.050605
train step #150/296 acc: 0.656250, loss: 0.852172
train step #200/296 acc: 0.578125, loss: 1.216218
train step #250/296 acc: 0.625000, loss: 0.923108
Validation acc: 0.672697, loss: 1.005843
saving best model ...
Test acc: 0.673564, loss: 0.952951
Cost time:37.435920s

Epoch: 3
train step #0/296 acc: 0.593750, loss: 0.938679
train step #50/296 acc: 0.593750, loss: 0.901293
train step #100/296 acc: 0.750000, loss: 0.955268
train step #150/296 acc: 0.703125, loss: 0.793244
train step #200/296 acc: 0.625000, loss: 1.121191
train step #250/296 acc: 0.656250, loss: 0.843831
Validation acc: 0.672286, loss: 0.922961
Test acc: 0.699324, loss: 0.865696
Cost time:38.082868s

Epoch: 4
train step #0/296 acc: 0.671875, loss: 0.843413
train step #50/296 acc: 0.640625, loss: 0.809164
train step #100/296 acc: 0.734375, loss: 0.888769
train step #150/296 acc: 0.750000, loss: 0.740394
train step #200/296 acc: 0.687500, loss: 1.034733
train step #250/296 acc: 0.750000, loss: 0.759550
Validation acc: 0.703947, loss: 0.894556
saving best model ...
Test acc: 0.712416, loss: 0.837180
Cost time:38.201253s

Epoch: 5
train step #0/296 acc: 0.656250, loss: 0.823279
train step #50/296 acc: 0.687500, loss: 0.757493
train step #100/296 acc: 0.703125, loss: 0.832725
train step #150/296 acc: 0.765625, loss: 0.697237
train step #200/296 acc: 0.687500, loss: 1.024799
train step #250/296 acc: 0.734375, loss: 0.747009
Validation acc: 0.711349, loss: 0.865472
saving best model ...
Test acc: 0.716639, loss: 0.808013
Cost time:37.111969s

Epoch: 6
train step #0/296 acc: 0.703125, loss: 0.808959
train step #50/296 acc: 0.687500, loss: 0.733255
train step #100/296 acc: 0.687500, loss: 0.813943
train step #150/296 acc: 0.781250, loss: 0.648717
train step #200/296 acc: 0.687500, loss: 1.015712
train step #250/296 acc: 0.765625, loss: 0.688204
Validation acc: 0.705592, loss: 0.871523
Test acc: 0.711571, loss: 0.822713
Cost time:37.666662s

Epoch: 7
train step #0/296 acc: 0.718750, loss: 0.771346
train step #50/296 acc: 0.656250, loss: 0.703591
train step #100/296 acc: 0.687500, loss: 0.801275
train step #150/296 acc: 0.765625, loss: 0.626015
train step #200/296 acc: 0.703125, loss: 0.990145
train step #250/296 acc: 0.781250, loss: 0.678366
Validation acc: 0.716694, loss: 0.838774
saving best model ...
Test acc: 0.720439, loss: 0.796701
Cost time:37.346285s

Epoch: 8
train step #0/296 acc: 0.765625, loss: 0.706567
train step #50/296 acc: 0.703125, loss: 0.642235
train step #100/296 acc: 0.718750, loss: 0.772371
train step #150/296 acc: 0.781250, loss: 0.606880
train step #200/296 acc: 0.718750, loss: 0.933630
train step #250/296 acc: 0.781250, loss: 0.652460
Validation acc: 0.728207, loss: 0.804961
saving best model ...
Test acc: 0.736064, loss: 0.761359
Cost time:37.445014s

Epoch: 9
train step #0/296 acc: 0.734375, loss: 0.681017
train step #50/296 acc: 0.703125, loss: 0.647667
train step #100/296 acc: 0.734375, loss: 0.752939
train step #150/296 acc: 0.781250, loss: 0.602129
train step #200/296 acc: 0.687500, loss: 0.924187
train step #250/296 acc: 0.781250, loss: 0.611940
Validation acc: 0.727385, loss: 0.804351
Test acc: 0.736909, loss: 0.752348
Cost time:37.631551s

Epoch: 10
train step #0/296 acc: 0.781250, loss: 0.661864
train step #50/296 acc: 0.703125, loss: 0.640526
train step #100/296 acc: 0.718750, loss: 0.741626
train step #150/296 acc: 0.812500, loss: 0.597885
train step #200/296 acc: 0.718750, loss: 0.893188
train step #250/296 acc: 0.781250, loss: 0.582295
Validation acc: 0.728207, loss: 0.803786
saving best model ...
Test acc: 0.736064, loss: 0.751662
Cost time:36.810470s

Epoch: 11
train step #0/296 acc: 0.781250, loss: 0.647492
train step #50/296 acc: 0.734375, loss: 0.614752
train step #100/296 acc: 0.765625, loss: 0.703520
train step #150/296 acc: 0.796875, loss: 0.597618
train step #200/296 acc: 0.718750, loss: 0.869340
train step #250/296 acc: 0.859375, loss: 0.548075
Validation acc: 0.726974, loss: 0.809469
Test acc: 0.743666, loss: 0.745561
Cost time:37.488447s

Epoch: 12
train step #0/296 acc: 0.781250, loss: 0.632838
train step #50/296 acc: 0.734375, loss: 0.646954
train step #100/296 acc: 0.750000, loss: 0.669905
train step #150/296 acc: 0.812500, loss: 0.569520
train step #200/296 acc: 0.750000, loss: 0.816310
train step #250/296 acc: 0.828125, loss: 0.530975
Validation acc: 0.713816, loss: 0.854727
Test acc: 0.729307, loss: 0.791028
Cost time:37.845338s

Epoch: 13
train step #0/296 acc: 0.765625, loss: 0.668821
train step #50/296 acc: 0.734375, loss: 0.629891
train step #100/296 acc: 0.781250, loss: 0.631925
train step #150/296 acc: 0.812500, loss: 0.518089
train step #200/296 acc: 0.765625, loss: 0.789740
train step #250/296 acc: 0.812500, loss: 0.521324
Validation acc: 0.720395, loss: 0.844782
Test acc: 0.717061, loss: 0.799866
Cost time:36.775252s

Epoch: 14
train step #0/296 acc: 0.765625, loss: 0.600652
train step #50/296 acc: 0.718750, loss: 0.593427
train step #100/296 acc: 0.781250, loss: 0.660904
train step #150/296 acc: 0.812500, loss: 0.525124
train step #200/296 acc: 0.765625, loss: 0.737423
train step #250/296 acc: 0.859375, loss: 0.515159
Validation acc: 0.711760, loss: 0.861358
Test acc: 0.715794, loss: 0.827598
Cost time:37.610618s

Epoch: 15
train step #0/296 acc: 0.781250, loss: 0.570326
train step #50/296 acc: 0.781250, loss: 0.529177
train step #100/296 acc: 0.765625, loss: 0.671741
train step #150/296 acc: 0.812500, loss: 0.533568
train step #200/296 acc: 0.781250, loss: 0.667112
train step #250/296 acc: 0.859375, loss: 0.510584
Validation acc: 0.714227, loss: 0.859482
Test acc: 0.727196, loss: 0.822047
Cost time:37.053777s

Epoch: 16
train step #0/296 acc: 0.765625, loss: 0.565044
train step #50/296 acc: 0.843750, loss: 0.482339
train step #100/296 acc: 0.750000, loss: 0.645626
train step #150/296 acc: 0.796875, loss: 0.524587
train step #200/296 acc: 0.796875, loss: 0.646663
train step #250/296 acc: 0.859375, loss: 0.487854
Validation acc: 0.715461, loss: 0.862566
Test acc: 0.724662, loss: 0.821711
Cost time:37.661340s

Epoch: 17
train step #0/296 acc: 0.781250, loss: 0.558562
train step #50/296 acc: 0.828125, loss: 0.473234
train step #100/296 acc: 0.765625, loss: 0.633473
train step #150/296 acc: 0.828125, loss: 0.447958
train step #200/296 acc: 0.796875, loss: 0.641827
train step #250/296 acc: 0.859375, loss: 0.481967
Validation acc: 0.709293, loss: 0.874565
Test acc: 0.719595, loss: 0.833406
Cost time:37.978513s

Epoch: 18
train step #0/296 acc: 0.765625, loss: 0.555728
train step #50/296 acc: 0.796875, loss: 0.460136
train step #100/296 acc: 0.781250, loss: 0.634304
train step #150/296 acc: 0.890625, loss: 0.412762
train step #200/296 acc: 0.796875, loss: 0.610802
train step #250/296 acc: 0.906250, loss: 0.462625
Validation acc: 0.717516, loss: 0.898355
Test acc: 0.719172, loss: 0.850978
Cost time:37.566462s

Epoch: 19
train step #0/296 acc: 0.765625, loss: 0.542060
train step #50/296 acc: 0.812500, loss: 0.449801
train step #100/296 acc: 0.796875, loss: 0.617268
train step #150/296 acc: 0.859375, loss: 0.381124
train step #200/296 acc: 0.812500, loss: 0.597669
train step #250/296 acc: 0.796875, loss: 0.467729
Validation acc: 0.716694, loss: 0.896636
Test acc: 0.724662, loss: 0.842977
Cost time:37.592985s

Epoch: 20
train step #0/296 acc: 0.796875, loss: 0.510907
train step #50/296 acc: 0.812500, loss: 0.484430
train step #100/296 acc: 0.781250, loss: 0.635520
train step #150/296 acc: 0.843750, loss: 0.426313
train step #200/296 acc: 0.796875, loss: 0.536884
train step #250/296 acc: 0.890625, loss: 0.392474
Validation acc: 0.713816, loss: 0.923538
Test acc: 0.729730, loss: 0.867355
Cost time:37.612605s

Test acc: 0.736064, loss: 0.751662
Best validation acc:0.728207
