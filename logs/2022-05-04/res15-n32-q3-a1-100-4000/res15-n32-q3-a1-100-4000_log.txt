Date: 2022-05-04 05:29:21.240565 

Model name: res15
Dataset: n32-q3-a1-100-4000
Input shape: (32, 100)
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 45, 32, 100]             405
            Conv2d-2          [-1, 45, 32, 100]          18,225
       BatchNorm2d-3          [-1, 45, 32, 100]               0
            Conv2d-4          [-1, 45, 32, 100]          18,225
       BatchNorm2d-5          [-1, 45, 32, 100]               0
            Conv2d-6          [-1, 45, 32, 100]          18,225
       BatchNorm2d-7          [-1, 45, 32, 100]               0
            Conv2d-8          [-1, 45, 32, 100]          18,225
       BatchNorm2d-9          [-1, 45, 32, 100]               0
           Conv2d-10          [-1, 45, 32, 100]          18,225
      BatchNorm2d-11          [-1, 45, 32, 100]               0
           Conv2d-12          [-1, 45, 32, 100]          18,225
      BatchNorm2d-13          [-1, 45, 32, 100]               0
           Conv2d-14          [-1, 45, 32, 100]          18,225
      BatchNorm2d-15          [-1, 45, 32, 100]               0
           Conv2d-16          [-1, 45, 32, 100]          18,225
      BatchNorm2d-17          [-1, 45, 32, 100]               0
           Conv2d-18          [-1, 45, 32, 100]          18,225
      BatchNorm2d-19          [-1, 45, 32, 100]               0
           Conv2d-20          [-1, 45, 32, 100]          18,225
      BatchNorm2d-21          [-1, 45, 32, 100]               0
           Conv2d-22          [-1, 45, 32, 100]          18,225
      BatchNorm2d-23          [-1, 45, 32, 100]               0
           Conv2d-24          [-1, 45, 32, 100]          18,225
      BatchNorm2d-25          [-1, 45, 32, 100]               0
           Conv2d-26          [-1, 45, 32, 100]          18,225
      BatchNorm2d-27          [-1, 45, 32, 100]               0
           Linear-28                   [-1, 10]             460
================================================================
Total params: 237,790
Trainable params: 237,790
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 29.66
Params size (MB): 0.91
Estimated Total Size (MB): 30.58
----------------------------------------------------------------
traning sample:18945
validation sample:2369
testing sample:2368

Using gpu: Tesla K80
Training epoches: 20
Training batches: 296

Epoch: 1
train step #0/296 acc: 0.078125, loss: 2.305234
train step #50/296 acc: 0.531250, loss: 1.393216
train step #100/296 acc: 0.796875, loss: 0.917149
train step #150/296 acc: 0.796875, loss: 0.646343
train step #200/296 acc: 0.843750, loss: 0.651589
train step #250/296 acc: 0.843750, loss: 0.480554
Validation acc: 0.809622, loss: 0.581819
saving best model ...
Test acc: 0.805321, loss: 0.604169
Cost time:528.404786s

Epoch: 2
train step #0/296 acc: 0.937500, loss: 0.252327
train step #50/296 acc: 0.906250, loss: 0.463080
train step #100/296 acc: 0.921875, loss: 0.269589
train step #150/296 acc: 0.890625, loss: 0.263261
train step #200/296 acc: 0.875000, loss: 0.347173
train step #250/296 acc: 0.890625, loss: 0.296072
Validation acc: 0.913240, loss: 0.285948
saving best model ...
Test acc: 0.901182, loss: 0.317221
Cost time:159.369021s

Epoch: 3
train step #0/296 acc: 1.000000, loss: 0.072470
train step #50/296 acc: 0.875000, loss: 0.310531
train step #100/296 acc: 0.953125, loss: 0.147826
train step #150/296 acc: 0.921875, loss: 0.188496
train step #200/296 acc: 0.937500, loss: 0.211309
train step #250/296 acc: 0.921875, loss: 0.260840
Validation acc: 0.935444, loss: 0.209171
saving best model ...
Test acc: 0.926098, loss: 0.227573
Cost time:159.110667s

Epoch: 4
train step #0/296 acc: 0.984375, loss: 0.076886
train step #50/296 acc: 0.921875, loss: 0.284223
train step #100/296 acc: 0.921875, loss: 0.199859
train step #150/296 acc: 0.921875, loss: 0.180869
train step #200/296 acc: 0.921875, loss: 0.236991
train step #250/296 acc: 0.921875, loss: 0.192301
Validation acc: 0.904605, loss: 0.276368
Test acc: 0.898226, loss: 0.304104
Cost time:159.330581s

Epoch: 5
train step #0/296 acc: 0.984375, loss: 0.089268
train step #50/296 acc: 0.906250, loss: 0.265696
train step #100/296 acc: 0.921875, loss: 0.206071
train step #150/296 acc: 0.937500, loss: 0.158849
train step #200/296 acc: 0.921875, loss: 0.209016
train step #250/296 acc: 0.937500, loss: 0.130667
Validation acc: 0.918174, loss: 0.232373
Test acc: 0.920186, loss: 0.240983
Cost time:159.240699s

Epoch: 6
train step #0/296 acc: 0.968750, loss: 0.079273
train step #50/296 acc: 0.921875, loss: 0.212633
train step #100/296 acc: 0.937500, loss: 0.143755
train step #150/296 acc: 0.968750, loss: 0.116571
train step #200/296 acc: 0.968750, loss: 0.146065
train step #250/296 acc: 0.921875, loss: 0.147966
Validation acc: 0.943257, loss: 0.186507
saving best model ...
Test acc: 0.941723, loss: 0.197604
Cost time:159.325367s

Epoch: 7
train step #0/296 acc: 0.968750, loss: 0.085841
train step #50/296 acc: 0.937500, loss: 0.188066
train step #100/296 acc: 0.953125, loss: 0.160020
train step #150/296 acc: 0.984375, loss: 0.072234
train step #200/296 acc: 0.953125, loss: 0.141483
train step #250/296 acc: 0.968750, loss: 0.093189
Validation acc: 0.955181, loss: 0.144761
saving best model ...
Test acc: 0.948480, loss: 0.168548
Cost time:159.348320s

Epoch: 8
train step #0/296 acc: 0.968750, loss: 0.044686
train step #50/296 acc: 0.937500, loss: 0.181407
train step #100/296 acc: 0.937500, loss: 0.177195
train step #150/296 acc: 0.953125, loss: 0.102288
train step #200/296 acc: 0.953125, loss: 0.120578
train step #250/296 acc: 0.968750, loss: 0.090087
Validation acc: 0.957648, loss: 0.142758
saving best model ...
Test acc: 0.951014, loss: 0.154335
Cost time:159.063571s

Epoch: 9
train step #0/296 acc: 0.984375, loss: 0.027235
train step #50/296 acc: 0.921875, loss: 0.198390
train step #100/296 acc: 0.953125, loss: 0.134479
train step #150/296 acc: 1.000000, loss: 0.051349
train step #200/296 acc: 0.953125, loss: 0.102671
train step #250/296 acc: 0.984375, loss: 0.073383
Validation acc: 0.958059, loss: 0.153400
saving best model ...
Test acc: 0.951858, loss: 0.170727
Cost time:159.124978s

Epoch: 10
train step #0/296 acc: 0.984375, loss: 0.028034
train step #50/296 acc: 0.937500, loss: 0.183239
train step #100/296 acc: 0.968750, loss: 0.113946
train step #150/296 acc: 1.000000, loss: 0.065011
train step #200/296 acc: 0.968750, loss: 0.093880
train step #250/296 acc: 0.984375, loss: 0.052319
Validation acc: 0.954359, loss: 0.154736
Test acc: 0.943834, loss: 0.169957
Cost time:159.063295s

Epoch: 11
train step #0/296 acc: 0.984375, loss: 0.056576
train step #50/296 acc: 0.953125, loss: 0.155374
train step #100/296 acc: 0.968750, loss: 0.109957
train step #150/296 acc: 0.968750, loss: 0.095009
train step #200/296 acc: 0.953125, loss: 0.106466
train step #250/296 acc: 0.984375, loss: 0.074307
Validation acc: 0.939967, loss: 0.198589
Test acc: 0.929899, loss: 0.236916
Cost time:159.065842s

Epoch: 12
train step #0/296 acc: 0.937500, loss: 0.073064
train step #50/296 acc: 0.937500, loss: 0.150415
train step #100/296 acc: 0.968750, loss: 0.163618
train step #150/296 acc: 1.000000, loss: 0.043377
train step #200/296 acc: 0.953125, loss: 0.094353
train step #250/296 acc: 0.968750, loss: 0.079106
Validation acc: 0.944079, loss: 0.175000
Test acc: 0.938345, loss: 0.202633
Cost time:159.076581s

Epoch: 13
train step #0/296 acc: 1.000000, loss: 0.017743
train step #50/296 acc: 0.953125, loss: 0.141896
train step #100/296 acc: 0.953125, loss: 0.129030
train step #150/296 acc: 1.000000, loss: 0.018338
train step #200/296 acc: 0.968750, loss: 0.084136
train step #250/296 acc: 0.968750, loss: 0.057111
Validation acc: 0.940789, loss: 0.180691
Test acc: 0.937078, loss: 0.205971
Cost time:158.946585s

Epoch: 14
train step #0/296 acc: 1.000000, loss: 0.015256
train step #50/296 acc: 0.937500, loss: 0.153634
train step #100/296 acc: 0.968750, loss: 0.086019
train step #150/296 acc: 1.000000, loss: 0.022960
train step #200/296 acc: 0.968750, loss: 0.074933
train step #250/296 acc: 0.984375, loss: 0.074805
Validation acc: 0.945312, loss: 0.180612
Test acc: 0.937922, loss: 0.200225
Cost time:158.981894s

Epoch: 15
train step #0/296 acc: 1.000000, loss: 0.015682
train step #50/296 acc: 0.968750, loss: 0.151735
train step #100/296 acc: 0.968750, loss: 0.095263
train step #150/296 acc: 1.000000, loss: 0.036120
train step #200/296 acc: 0.968750, loss: 0.089056
train step #250/296 acc: 0.984375, loss: 0.070784
Validation acc: 0.956826, loss: 0.148264
Test acc: 0.948902, loss: 0.177145
Cost time:159.313233s

Epoch: 16
train step #0/296 acc: 1.000000, loss: 0.011812
train step #50/296 acc: 0.953125, loss: 0.151741
train step #100/296 acc: 0.937500, loss: 0.152373
train step #150/296 acc: 1.000000, loss: 0.036409
train step #200/296 acc: 0.984375, loss: 0.046995
train step #250/296 acc: 0.984375, loss: 0.070527
Validation acc: 0.951480, loss: 0.144359
Test acc: 0.952280, loss: 0.156232
Cost time:159.112512s

Epoch: 17
train step #0/296 acc: 1.000000, loss: 0.015950
train step #50/296 acc: 0.968750, loss: 0.120084
train step #100/296 acc: 0.968750, loss: 0.113685
train step #150/296 acc: 1.000000, loss: 0.019895
train step #200/296 acc: 0.984375, loss: 0.071752
train step #250/296 acc: 0.984375, loss: 0.074206
Validation acc: 0.946135, loss: 0.187896
Test acc: 0.941723, loss: 0.186395
Cost time:159.296556s

Epoch: 18
train step #0/296 acc: 0.984375, loss: 0.025320
train step #50/296 acc: 0.937500, loss: 0.179116
train step #100/296 acc: 0.968750, loss: 0.093114
train step #150/296 acc: 1.000000, loss: 0.012199
train step #200/296 acc: 1.000000, loss: 0.045503
train step #250/296 acc: 1.000000, loss: 0.023374
Validation acc: 0.926398, loss: 0.261663
Test acc: 0.923142, loss: 0.265832
Cost time:159.450938s

Epoch: 19
train step #0/296 acc: 1.000000, loss: 0.014648
train step #50/296 acc: 0.953125, loss: 0.136142
train step #100/296 acc: 0.968750, loss: 0.091078
train step #150/296 acc: 1.000000, loss: 0.007690
train step #200/296 acc: 1.000000, loss: 0.021216
train step #250/296 acc: 1.000000, loss: 0.028116
Validation acc: 0.949836, loss: 0.174233
Test acc: 0.940034, loss: 0.202425
Cost time:158.970661s

Epoch: 20
train step #0/296 acc: 0.984375, loss: 0.027599
train step #50/296 acc: 0.953125, loss: 0.145259
train step #100/296 acc: 0.968750, loss: 0.071947
train step #150/296 acc: 1.000000, loss: 0.008497
train step #200/296 acc: 1.000000, loss: 0.026727
train step #250/296 acc: 1.000000, loss: 0.059270
Validation acc: 0.952303, loss: 0.169133
Test acc: 0.950169, loss: 0.172318
Cost time:159.106785s

Test acc: 0.951858, loss: 0.170727
Best validation acc:0.958059
