Date: 2022-05-07 05:44:25.516967 

Model name: res15
Dataset: n32-q2.5-a1-100-4000
Input shape: (32, 100)
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 45, 32, 100]             405
            Conv2d-2          [-1, 45, 32, 100]          18,225
       BatchNorm2d-3          [-1, 45, 32, 100]               0
            Conv2d-4          [-1, 45, 32, 100]          18,225
       BatchNorm2d-5          [-1, 45, 32, 100]               0
            Conv2d-6          [-1, 45, 32, 100]          18,225
       BatchNorm2d-7          [-1, 45, 32, 100]               0
            Conv2d-8          [-1, 45, 32, 100]          18,225
       BatchNorm2d-9          [-1, 45, 32, 100]               0
           Conv2d-10          [-1, 45, 32, 100]          18,225
      BatchNorm2d-11          [-1, 45, 32, 100]               0
           Conv2d-12          [-1, 45, 32, 100]          18,225
      BatchNorm2d-13          [-1, 45, 32, 100]               0
           Conv2d-14          [-1, 45, 32, 100]          18,225
      BatchNorm2d-15          [-1, 45, 32, 100]               0
           Conv2d-16          [-1, 45, 32, 100]          18,225
      BatchNorm2d-17          [-1, 45, 32, 100]               0
           Conv2d-18          [-1, 45, 32, 100]          18,225
      BatchNorm2d-19          [-1, 45, 32, 100]               0
           Conv2d-20          [-1, 45, 32, 100]          18,225
      BatchNorm2d-21          [-1, 45, 32, 100]               0
           Conv2d-22          [-1, 45, 32, 100]          18,225
      BatchNorm2d-23          [-1, 45, 32, 100]               0
           Conv2d-24          [-1, 45, 32, 100]          18,225
      BatchNorm2d-25          [-1, 45, 32, 100]               0
           Conv2d-26          [-1, 45, 32, 100]          18,225
      BatchNorm2d-27          [-1, 45, 32, 100]               0
           Linear-28                   [-1, 10]             460
================================================================
Total params: 237,790
Trainable params: 237,790
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 29.66
Params size (MB): 0.91
Estimated Total Size (MB): 30.58
----------------------------------------------------------------
traning sample:18945
validation sample:2369
testing sample:2368

Using gpu: Tesla K80
Training epoches: 20
Training batches: 296

Epoch: 1
train step #0/296 acc: 0.156250, loss: 2.279319
train step #50/296 acc: 0.625000, loss: 1.301620
train step #100/296 acc: 0.750000, loss: 0.851943
train step #150/296 acc: 0.843750, loss: 0.649926
train step #200/296 acc: 0.875000, loss: 0.509057
train step #250/296 acc: 0.843750, loss: 0.477084
Validation acc: 0.779605, loss: 0.645723
saving best model ...
Test acc: 0.804899, loss: 0.595187
Cost time:535.651015s

Epoch: 2
train step #0/296 acc: 0.859375, loss: 0.437861
train step #50/296 acc: 0.921875, loss: 0.283461
train step #100/296 acc: 0.953125, loss: 0.251136
train step #150/296 acc: 0.890625, loss: 0.288589
train step #200/296 acc: 0.906250, loss: 0.326691
train step #250/296 acc: 0.937500, loss: 0.314276
Validation acc: 0.905016, loss: 0.319037
saving best model ...
Test acc: 0.911318, loss: 0.303134
Cost time:156.080744s

Epoch: 3
train step #0/296 acc: 0.875000, loss: 0.315872
train step #50/296 acc: 0.968750, loss: 0.162673
train step #100/296 acc: 0.968750, loss: 0.178090
train step #150/296 acc: 0.937500, loss: 0.174412
train step #200/296 acc: 0.906250, loss: 0.290251
train step #250/296 acc: 0.890625, loss: 0.285784
Validation acc: 0.862664, loss: 0.420904
Test acc: 0.858530, loss: 0.420379
Cost time:155.666548s

Epoch: 4
train step #0/296 acc: 0.906250, loss: 0.270298
train step #50/296 acc: 0.968750, loss: 0.131462
train step #100/296 acc: 0.968750, loss: 0.144210
train step #150/296 acc: 0.968750, loss: 0.140495
train step #200/296 acc: 0.921875, loss: 0.265878
train step #250/296 acc: 0.906250, loss: 0.243395
Validation acc: 0.921053, loss: 0.259890
saving best model ...
Test acc: 0.922720, loss: 0.244178
Cost time:156.141676s

Epoch: 5
train step #0/296 acc: 0.921875, loss: 0.237397
train step #50/296 acc: 0.953125, loss: 0.124524
train step #100/296 acc: 0.968750, loss: 0.127150
train step #150/296 acc: 0.937500, loss: 0.161388
train step #200/296 acc: 0.937500, loss: 0.202673
train step #250/296 acc: 0.906250, loss: 0.249292
Validation acc: 0.930921, loss: 0.222121
saving best model ...
Test acc: 0.938767, loss: 0.193514
Cost time:156.058309s

Epoch: 6
train step #0/296 acc: 0.921875, loss: 0.230442
train step #50/296 acc: 0.937500, loss: 0.106662
train step #100/296 acc: 0.968750, loss: 0.116813
train step #150/296 acc: 0.968750, loss: 0.131308
train step #200/296 acc: 0.937500, loss: 0.207926
train step #250/296 acc: 0.890625, loss: 0.222743
Validation acc: 0.927632, loss: 0.232046
Test acc: 0.927365, loss: 0.217025
Cost time:155.553642s

Epoch: 7
train step #0/296 acc: 0.921875, loss: 0.182179
train step #50/296 acc: 0.984375, loss: 0.064501
train step #100/296 acc: 0.968750, loss: 0.112165
train step #150/296 acc: 0.968750, loss: 0.069506
train step #200/296 acc: 0.937500, loss: 0.191113
train step #250/296 acc: 0.937500, loss: 0.156354
Validation acc: 0.944901, loss: 0.179808
saving best model ...
Test acc: 0.943834, loss: 0.171744
Cost time:155.360275s

Epoch: 8
train step #0/296 acc: 0.937500, loss: 0.165200
train step #50/296 acc: 1.000000, loss: 0.034191
train step #100/296 acc: 0.968750, loss: 0.121526
train step #150/296 acc: 0.953125, loss: 0.093243
train step #200/296 acc: 0.937500, loss: 0.138523
train step #250/296 acc: 0.921875, loss: 0.175698
Validation acc: 0.930099, loss: 0.230944
Test acc: 0.927787, loss: 0.220505
Cost time:155.845059s

Epoch: 9
train step #0/296 acc: 0.937500, loss: 0.148989
train step #50/296 acc: 1.000000, loss: 0.037841
train step #100/296 acc: 0.968750, loss: 0.114496
train step #150/296 acc: 1.000000, loss: 0.058640
train step #200/296 acc: 0.937500, loss: 0.141841
train step #250/296 acc: 0.937500, loss: 0.154483
Validation acc: 0.936678, loss: 0.204082
Test acc: 0.937500, loss: 0.185522
Cost time:156.019607s

Epoch: 10
train step #0/296 acc: 0.937500, loss: 0.116485
train step #50/296 acc: 0.984375, loss: 0.057113
train step #100/296 acc: 0.953125, loss: 0.112054
train step #150/296 acc: 1.000000, loss: 0.063989
train step #200/296 acc: 0.953125, loss: 0.116891
train step #250/296 acc: 0.937500, loss: 0.161391
Validation acc: 0.932977, loss: 0.216197
Test acc: 0.934544, loss: 0.206801
Cost time:155.529620s

Epoch: 11
train step #0/296 acc: 0.953125, loss: 0.103156
train step #50/296 acc: 1.000000, loss: 0.048350
train step #100/296 acc: 0.968750, loss: 0.086983
train step #150/296 acc: 1.000000, loss: 0.047178
train step #200/296 acc: 0.968750, loss: 0.113176
train step #250/296 acc: 0.906250, loss: 0.198409
Validation acc: 0.932155, loss: 0.233572
Test acc: 0.932855, loss: 0.209552
Cost time:155.749871s

Epoch: 12
train step #0/296 acc: 0.968750, loss: 0.112798
train step #50/296 acc: 0.984375, loss: 0.052716
train step #100/296 acc: 0.968750, loss: 0.079538
train step #150/296 acc: 1.000000, loss: 0.024340
train step #200/296 acc: 0.968750, loss: 0.111293
train step #250/296 acc: 0.921875, loss: 0.171128
Validation acc: 0.938734, loss: 0.203747
Test acc: 0.943834, loss: 0.173836
Cost time:155.442609s

Epoch: 13
train step #0/296 acc: 0.968750, loss: 0.089118
train step #50/296 acc: 0.984375, loss: 0.038712
train step #100/296 acc: 1.000000, loss: 0.055567
train step #150/296 acc: 0.984375, loss: 0.047329
train step #200/296 acc: 0.968750, loss: 0.098653
train step #250/296 acc: 0.953125, loss: 0.101721
Validation acc: 0.946135, loss: 0.178694
saving best model ...
Test acc: 0.949324, loss: 0.159917
Cost time:155.784099s

Epoch: 14
train step #0/296 acc: 0.968750, loss: 0.097255
train step #50/296 acc: 0.953125, loss: 0.083216
train step #100/296 acc: 0.984375, loss: 0.047298
train step #150/296 acc: 0.984375, loss: 0.056914
train step #200/296 acc: 0.968750, loss: 0.145828
train step #250/296 acc: 0.953125, loss: 0.143532
Validation acc: 0.933799, loss: 0.223402
Test acc: 0.939189, loss: 0.195936
Cost time:156.370593s

Epoch: 15
train step #0/296 acc: 0.968750, loss: 0.100579
train step #50/296 acc: 1.000000, loss: 0.024026
train step #100/296 acc: 0.984375, loss: 0.039830
train step #150/296 acc: 1.000000, loss: 0.010019
train step #200/296 acc: 0.937500, loss: 0.120939
train step #250/296 acc: 0.968750, loss: 0.091071
Validation acc: 0.939145, loss: 0.201452
Test acc: 0.948057, loss: 0.172872
Cost time:156.208211s

Epoch: 16
train step #0/296 acc: 0.984375, loss: 0.056879
train step #50/296 acc: 1.000000, loss: 0.021555
train step #100/296 acc: 0.953125, loss: 0.104033
train step #150/296 acc: 1.000000, loss: 0.021191
train step #200/296 acc: 0.968750, loss: 0.078252
train step #250/296 acc: 0.906250, loss: 0.179664
Validation acc: 0.945312, loss: 0.173286
Test acc: 0.956081, loss: 0.145734
Cost time:156.609148s

Epoch: 17
train step #0/296 acc: 0.953125, loss: 0.120789
train step #50/296 acc: 0.968750, loss: 0.044546
train step #100/296 acc: 0.984375, loss: 0.044814
train step #150/296 acc: 1.000000, loss: 0.033468
train step #200/296 acc: 0.984375, loss: 0.054043
train step #250/296 acc: 0.953125, loss: 0.137677
Validation acc: 0.940789, loss: 0.210462
Test acc: 0.944679, loss: 0.185027
Cost time:156.008848s

Epoch: 18
train step #0/296 acc: 0.984375, loss: 0.049654
train step #50/296 acc: 0.984375, loss: 0.049160
train step #100/296 acc: 0.984375, loss: 0.028659
train step #150/296 acc: 1.000000, loss: 0.012280
train step #200/296 acc: 0.953125, loss: 0.069843
train step #250/296 acc: 0.968750, loss: 0.083123
Validation acc: 0.928454, loss: 0.254954
Test acc: 0.943412, loss: 0.218442
Cost time:156.174889s

Epoch: 19
train step #0/296 acc: 0.968750, loss: 0.079715
train step #50/296 acc: 0.968750, loss: 0.069331
train step #100/296 acc: 0.984375, loss: 0.046875
train step #150/296 acc: 0.984375, loss: 0.030338
train step #200/296 acc: 0.953125, loss: 0.092392
train step #250/296 acc: 0.984375, loss: 0.066050
Validation acc: 0.946135, loss: 0.166781
saving best model ...
Test acc: 0.957770, loss: 0.144089
Cost time:156.461283s

Epoch: 20
train step #0/296 acc: 0.968750, loss: 0.076597
train step #50/296 acc: 0.984375, loss: 0.035936
train step #100/296 acc: 1.000000, loss: 0.022841
train step #150/296 acc: 1.000000, loss: 0.023502
train step #200/296 acc: 0.968750, loss: 0.060289
train step #250/296 acc: 0.968750, loss: 0.073887
Validation acc: 0.938734, loss: 0.217618
Test acc: 0.941301, loss: 0.179415
Cost time:155.824976s

Test acc: 0.957770, loss: 0.144089
Best validation acc:0.946135
