Date: 2022-05-07 20:18:26.046367 

Model name: res15
Dataset: n32-q20-a1-100-4000
Input shape: (32, 100)
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 45, 32, 100]             405
            Conv2d-2          [-1, 45, 32, 100]          18,225
       BatchNorm2d-3          [-1, 45, 32, 100]               0
            Conv2d-4          [-1, 45, 32, 100]          18,225
       BatchNorm2d-5          [-1, 45, 32, 100]               0
            Conv2d-6          [-1, 45, 32, 100]          18,225
       BatchNorm2d-7          [-1, 45, 32, 100]               0
            Conv2d-8          [-1, 45, 32, 100]          18,225
       BatchNorm2d-9          [-1, 45, 32, 100]               0
           Conv2d-10          [-1, 45, 32, 100]          18,225
      BatchNorm2d-11          [-1, 45, 32, 100]               0
           Conv2d-12          [-1, 45, 32, 100]          18,225
      BatchNorm2d-13          [-1, 45, 32, 100]               0
           Conv2d-14          [-1, 45, 32, 100]          18,225
      BatchNorm2d-15          [-1, 45, 32, 100]               0
           Conv2d-16          [-1, 45, 32, 100]          18,225
      BatchNorm2d-17          [-1, 45, 32, 100]               0
           Conv2d-18          [-1, 45, 32, 100]          18,225
      BatchNorm2d-19          [-1, 45, 32, 100]               0
           Conv2d-20          [-1, 45, 32, 100]          18,225
      BatchNorm2d-21          [-1, 45, 32, 100]               0
           Conv2d-22          [-1, 45, 32, 100]          18,225
      BatchNorm2d-23          [-1, 45, 32, 100]               0
           Conv2d-24          [-1, 45, 32, 100]          18,225
      BatchNorm2d-25          [-1, 45, 32, 100]               0
           Conv2d-26          [-1, 45, 32, 100]          18,225
      BatchNorm2d-27          [-1, 45, 32, 100]               0
           Linear-28                   [-1, 10]             460
================================================================
Total params: 237,790
Trainable params: 237,790
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 29.66
Params size (MB): 0.91
Estimated Total Size (MB): 30.58
----------------------------------------------------------------
traning sample:18945
validation sample:2369
testing sample:2368

Using gpu: Tesla K80
Training epoches: 20
Training batches: 296

Epoch: 1
train step #0/296 acc: 0.140625, loss: 2.289145
train step #50/296 acc: 0.671875, loss: 1.185885
train step #100/296 acc: 0.734375, loss: 0.915895
train step #150/296 acc: 0.859375, loss: 0.538312
train step #200/296 acc: 0.828125, loss: 0.542199
train step #250/296 acc: 0.906250, loss: 0.400206
Validation acc: 0.807155, loss: 0.609280
saving best model ...
Test acc: 0.816301, loss: 0.569868
Cost time:161.245044s

Epoch: 2
train step #0/296 acc: 0.921875, loss: 0.355297
train step #50/296 acc: 0.953125, loss: 0.239949
train step #100/296 acc: 0.906250, loss: 0.278049
train step #150/296 acc: 0.968750, loss: 0.144808
train step #200/296 acc: 0.937500, loss: 0.343168
train step #250/296 acc: 0.875000, loss: 0.336921
Validation acc: 0.887336, loss: 0.353730
saving best model ...
Test acc: 0.891470, loss: 0.346210
Cost time:156.359386s

Epoch: 3
train step #0/296 acc: 0.921875, loss: 0.269602
train step #50/296 acc: 0.968750, loss: 0.141228
train step #100/296 acc: 0.875000, loss: 0.282820
train step #150/296 acc: 0.953125, loss: 0.173926
train step #200/296 acc: 0.937500, loss: 0.350255
train step #250/296 acc: 0.890625, loss: 0.268358
Validation acc: 0.878289, loss: 0.393621
Test acc: 0.883868, loss: 0.365606
Cost time:156.459540s

Epoch: 4
train step #0/296 acc: 0.890625, loss: 0.224129
train step #50/296 acc: 0.984375, loss: 0.118254
train step #100/296 acc: 0.906250, loss: 0.242659
train step #150/296 acc: 0.953125, loss: 0.153608
train step #200/296 acc: 0.937500, loss: 0.270897
train step #250/296 acc: 0.953125, loss: 0.182954
Validation acc: 0.899260, loss: 0.311958
saving best model ...
Test acc: 0.897382, loss: 0.284437
Cost time:156.111515s

Epoch: 5
train step #0/296 acc: 0.906250, loss: 0.227845
train step #50/296 acc: 0.984375, loss: 0.079390
train step #100/296 acc: 0.921875, loss: 0.210620
train step #150/296 acc: 0.968750, loss: 0.068053
train step #200/296 acc: 0.953125, loss: 0.238971
train step #250/296 acc: 0.953125, loss: 0.158360
Validation acc: 0.877878, loss: 0.365921
Test acc: 0.888091, loss: 0.321101
Cost time:156.644331s

Epoch: 6
train step #0/296 acc: 0.937500, loss: 0.194749
train step #50/296 acc: 0.984375, loss: 0.070896
train step #100/296 acc: 0.921875, loss: 0.205193
train step #150/296 acc: 0.984375, loss: 0.043364
train step #200/296 acc: 0.937500, loss: 0.255794
train step #250/296 acc: 0.953125, loss: 0.123990
Validation acc: 0.932566, loss: 0.214003
saving best model ...
Test acc: 0.937500, loss: 0.179493
Cost time:157.071740s

Epoch: 7
train step #0/296 acc: 0.937500, loss: 0.151212
train step #50/296 acc: 0.984375, loss: 0.076834
train step #100/296 acc: 0.921875, loss: 0.190091
train step #150/296 acc: 0.968750, loss: 0.052072
train step #200/296 acc: 0.921875, loss: 0.253300
train step #250/296 acc: 1.000000, loss: 0.045958
Validation acc: 0.923520, loss: 0.239000
Test acc: 0.928209, loss: 0.201321
Cost time:156.296979s

Epoch: 8
train step #0/296 acc: 0.921875, loss: 0.154503
train step #50/296 acc: 0.984375, loss: 0.077660
train step #100/296 acc: 0.937500, loss: 0.199012
train step #150/296 acc: 1.000000, loss: 0.023371
train step #200/296 acc: 0.906250, loss: 0.253825
train step #250/296 acc: 0.984375, loss: 0.061178
Validation acc: 0.938734, loss: 0.186248
saving best model ...
Test acc: 0.940878, loss: 0.166050
Cost time:156.513007s

Epoch: 9
train step #0/296 acc: 0.953125, loss: 0.125021
train step #50/296 acc: 0.984375, loss: 0.063930
train step #100/296 acc: 0.937500, loss: 0.144329
train step #150/296 acc: 0.968750, loss: 0.073615
train step #200/296 acc: 0.937500, loss: 0.232110
train step #250/296 acc: 0.984375, loss: 0.049234
Validation acc: 0.917352, loss: 0.260047
Test acc: 0.924409, loss: 0.231961
Cost time:156.360034s

Epoch: 10
train step #0/296 acc: 0.953125, loss: 0.124783
train step #50/296 acc: 0.984375, loss: 0.068243
train step #100/296 acc: 0.906250, loss: 0.184758
train step #150/296 acc: 1.000000, loss: 0.012560
train step #200/296 acc: 0.953125, loss: 0.201273
train step #250/296 acc: 1.000000, loss: 0.028482
Validation acc: 0.932566, loss: 0.208026
Test acc: 0.940878, loss: 0.187384
Cost time:156.859953s

Epoch: 11
train step #0/296 acc: 0.968750, loss: 0.099029
train step #50/296 acc: 0.968750, loss: 0.079686
train step #100/296 acc: 0.937500, loss: 0.124373
train step #150/296 acc: 0.968750, loss: 0.133684
train step #200/296 acc: 0.937500, loss: 0.200961
train step #250/296 acc: 0.984375, loss: 0.049799
Validation acc: 0.939556, loss: 0.203968
saving best model ...
Test acc: 0.936655, loss: 0.196797
Cost time:157.172491s

Epoch: 12
train step #0/296 acc: 0.937500, loss: 0.156843
train step #50/296 acc: 0.984375, loss: 0.068830
train step #100/296 acc: 0.953125, loss: 0.103166
train step #150/296 acc: 0.968750, loss: 0.063053
train step #200/296 acc: 0.921875, loss: 0.241104
train step #250/296 acc: 1.000000, loss: 0.026377
Validation acc: 0.956826, loss: 0.134463
saving best model ...
Test acc: 0.952280, loss: 0.149350
Cost time:156.490108s

Epoch: 13
train step #0/296 acc: 0.968750, loss: 0.098714
train step #50/296 acc: 0.984375, loss: 0.053443
train step #100/296 acc: 0.953125, loss: 0.134156
train step #150/296 acc: 1.000000, loss: 0.009329
train step #200/296 acc: 0.968750, loss: 0.118197
train step #250/296 acc: 1.000000, loss: 0.035332
Validation acc: 0.940789, loss: 0.200997
Test acc: 0.935389, loss: 0.217612
Cost time:156.442307s

Epoch: 14
train step #0/296 acc: 0.937500, loss: 0.172433
train step #50/296 acc: 0.984375, loss: 0.061613
train step #100/296 acc: 0.937500, loss: 0.118094
train step #150/296 acc: 1.000000, loss: 0.008206
train step #200/296 acc: 0.953125, loss: 0.172222
train step #250/296 acc: 1.000000, loss: 0.026010
Validation acc: 0.964227, loss: 0.119568
saving best model ...
Test acc: 0.949324, loss: 0.150174
Cost time:156.468057s

Epoch: 15
train step #0/296 acc: 0.968750, loss: 0.099212
train step #50/296 acc: 0.984375, loss: 0.072883
train step #100/296 acc: 0.937500, loss: 0.160540
train step #150/296 acc: 1.000000, loss: 0.010886
train step #200/296 acc: 0.953125, loss: 0.093857
train step #250/296 acc: 1.000000, loss: 0.014254
Validation acc: 0.946957, loss: 0.188767
Test acc: 0.936233, loss: 0.213508
Cost time:156.709052s

Epoch: 16
train step #0/296 acc: 0.937500, loss: 0.145234
train step #50/296 acc: 0.984375, loss: 0.043376
train step #100/296 acc: 0.953125, loss: 0.102325
train step #150/296 acc: 1.000000, loss: 0.017585
train step #200/296 acc: 0.984375, loss: 0.081183
train step #250/296 acc: 1.000000, loss: 0.021436
Validation acc: 0.947780, loss: 0.181657
Test acc: 0.935811, loss: 0.240823
Cost time:156.811876s

Epoch: 17
train step #0/296 acc: 0.968750, loss: 0.081890
train step #50/296 acc: 0.984375, loss: 0.071771
train step #100/296 acc: 0.953125, loss: 0.084410
train step #150/296 acc: 1.000000, loss: 0.004910
train step #200/296 acc: 0.968750, loss: 0.065799
train step #250/296 acc: 0.968750, loss: 0.080671
Validation acc: 0.953947, loss: 0.160777
Test acc: 0.938345, loss: 0.207130
Cost time:156.736327s

Epoch: 18
train step #0/296 acc: 0.953125, loss: 0.108954
train step #50/296 acc: 0.984375, loss: 0.052292
train step #100/296 acc: 0.984375, loss: 0.065929
train step #150/296 acc: 0.984375, loss: 0.083285
train step #200/296 acc: 0.984375, loss: 0.047191
train step #250/296 acc: 1.000000, loss: 0.016951
Validation acc: 0.955592, loss: 0.150996
Test acc: 0.943834, loss: 0.183536
Cost time:156.605401s

Epoch: 19
train step #0/296 acc: 0.968750, loss: 0.084028
train step #50/296 acc: 0.953125, loss: 0.078221
train step #100/296 acc: 0.968750, loss: 0.078736
train step #150/296 acc: 1.000000, loss: 0.015505
train step #200/296 acc: 0.968750, loss: 0.054495
train step #250/296 acc: 1.000000, loss: 0.021275
Validation acc: 0.952303, loss: 0.155301
Test acc: 0.945101, loss: 0.161993
Cost time:156.700894s

Epoch: 20
train step #0/296 acc: 0.953125, loss: 0.114972
train step #50/296 acc: 0.984375, loss: 0.056310
train step #100/296 acc: 0.968750, loss: 0.067755
train step #150/296 acc: 1.000000, loss: 0.009288
train step #200/296 acc: 0.968750, loss: 0.095223
train step #250/296 acc: 1.000000, loss: 0.027433
Validation acc: 0.963405, loss: 0.130961
Test acc: 0.940034, loss: 0.180759
Cost time:156.537658s

Test acc: 0.949324, loss: 0.150174
Best validation acc:0.964227
