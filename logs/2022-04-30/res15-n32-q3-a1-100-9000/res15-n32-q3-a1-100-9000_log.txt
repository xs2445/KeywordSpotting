Date: 2022-05-01 03:42:46.194297 

Model name: res15
Dataset: n32-q3-a1-100-9000
Input shape: (32, 100)
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 45, 32, 100]             405
            Conv2d-2          [-1, 45, 32, 100]          18,225
       BatchNorm2d-3          [-1, 45, 32, 100]               0
            Conv2d-4          [-1, 45, 32, 100]          18,225
       BatchNorm2d-5          [-1, 45, 32, 100]               0
            Conv2d-6          [-1, 45, 32, 100]          18,225
       BatchNorm2d-7          [-1, 45, 32, 100]               0
            Conv2d-8          [-1, 45, 32, 100]          18,225
       BatchNorm2d-9          [-1, 45, 32, 100]               0
           Conv2d-10          [-1, 45, 32, 100]          18,225
      BatchNorm2d-11          [-1, 45, 32, 100]               0
           Conv2d-12          [-1, 45, 32, 100]          18,225
      BatchNorm2d-13          [-1, 45, 32, 100]               0
           Conv2d-14          [-1, 45, 32, 100]          18,225
      BatchNorm2d-15          [-1, 45, 32, 100]               0
           Conv2d-16          [-1, 45, 32, 100]          18,225
      BatchNorm2d-17          [-1, 45, 32, 100]               0
           Conv2d-18          [-1, 45, 32, 100]          18,225
      BatchNorm2d-19          [-1, 45, 32, 100]               0
           Conv2d-20          [-1, 45, 32, 100]          18,225
      BatchNorm2d-21          [-1, 45, 32, 100]               0
           Conv2d-22          [-1, 45, 32, 100]          18,225
      BatchNorm2d-23          [-1, 45, 32, 100]               0
           Conv2d-24          [-1, 45, 32, 100]          18,225
      BatchNorm2d-25          [-1, 45, 32, 100]               0
           Conv2d-26          [-1, 45, 32, 100]          18,225
      BatchNorm2d-27          [-1, 45, 32, 100]               0
           Linear-28                   [-1, 10]             460
================================================================
Total params: 237,790
Trainable params: 237,790
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 29.66
Params size (MB): 0.91
Estimated Total Size (MB): 30.58
----------------------------------------------------------------
traning sample:18945
validation sample:2369
testing sample:2368

Using gpu: Tesla K80
Training epoches: 15
Training batches: 296

Epoch: 1
train step #0/296 acc: 0.140625, loss: 2.295906
train step #50/296 acc: 0.703125, loss: 1.210479
train step #100/296 acc: 0.718750, loss: 0.877069
train step #150/296 acc: 0.765625, loss: 0.730381
train step #200/296 acc: 0.828125, loss: 0.476421
train step #250/296 acc: 0.859375, loss: 0.557809
Validation acc: 0.815789, loss: 0.606783
saving best model ...
Test acc: 0.812078, loss: 0.610828
Cost time:418.146311s

Epoch: 2
train step #0/296 acc: 0.890625, loss: 0.333658
train step #50/296 acc: 0.890625, loss: 0.392515
train step #100/296 acc: 0.906250, loss: 0.333712
train step #150/296 acc: 0.828125, loss: 0.417558
train step #200/296 acc: 0.921875, loss: 0.238822
train step #250/296 acc: 0.906250, loss: 0.447904
Validation acc: 0.894737, loss: 0.358409
saving best model ...
Test acc: 0.893159, loss: 0.335698
Cost time:193.777715s

Epoch: 3
train step #0/296 acc: 0.953125, loss: 0.199226
train step #50/296 acc: 0.921875, loss: 0.269052
train step #100/296 acc: 0.906250, loss: 0.265976
train step #150/296 acc: 0.906250, loss: 0.282763
train step #200/296 acc: 0.953125, loss: 0.177090
train step #250/296 acc: 0.906250, loss: 0.329322
Validation acc: 0.916530, loss: 0.269917
saving best model ...
Test acc: 0.922720, loss: 0.239985
Cost time:150.966768s

Epoch: 4
train step #0/296 acc: 0.953125, loss: 0.174011
train step #50/296 acc: 0.921875, loss: 0.198944
train step #100/296 acc: 0.937500, loss: 0.208174
train step #150/296 acc: 0.921875, loss: 0.209153
train step #200/296 acc: 0.953125, loss: 0.142501
train step #250/296 acc: 0.921875, loss: 0.274590
Validation acc: 0.930510, loss: 0.227699
saving best model ...
Test acc: 0.935811, loss: 0.197371
Cost time:150.720312s

Epoch: 5
train step #0/296 acc: 0.937500, loss: 0.180376
train step #50/296 acc: 0.968750, loss: 0.121813
train step #100/296 acc: 0.921875, loss: 0.202571
train step #150/296 acc: 0.968750, loss: 0.139095
train step #200/296 acc: 0.953125, loss: 0.103171
train step #250/296 acc: 0.937500, loss: 0.194163
Validation acc: 0.871711, loss: 0.467275
Test acc: 0.862331, loss: 0.435289
Cost time:150.715791s

Epoch: 6
train step #0/296 acc: 0.937500, loss: 0.176280
train step #50/296 acc: 0.968750, loss: 0.113039
train step #100/296 acc: 0.953125, loss: 0.156973
train step #150/296 acc: 0.968750, loss: 0.105853
train step #200/296 acc: 0.953125, loss: 0.109914
train step #250/296 acc: 0.937500, loss: 0.204733
Validation acc: 0.918997, loss: 0.264387
Test acc: 0.921030, loss: 0.249478
Cost time:150.738194s

Epoch: 7
train step #0/296 acc: 0.953125, loss: 0.135581
train step #50/296 acc: 0.968750, loss: 0.102521
train step #100/296 acc: 0.937500, loss: 0.163887
train step #150/296 acc: 0.984375, loss: 0.109134
train step #200/296 acc: 0.968750, loss: 0.090281
train step #250/296 acc: 0.953125, loss: 0.225404
Validation acc: 0.942434, loss: 0.181365
saving best model ...
Test acc: 0.947213, loss: 0.158785
Cost time:151.117309s

Epoch: 8
train step #0/296 acc: 0.953125, loss: 0.123875
train step #50/296 acc: 0.953125, loss: 0.128704
train step #100/296 acc: 0.953125, loss: 0.195048
train step #150/296 acc: 0.953125, loss: 0.119530
train step #200/296 acc: 0.968750, loss: 0.084753
train step #250/296 acc: 0.937500, loss: 0.182521
Validation acc: 0.938322, loss: 0.189872
Test acc: 0.950169, loss: 0.156498
Cost time:151.531676s

Epoch: 9
train step #0/296 acc: 0.968750, loss: 0.096734
train step #50/296 acc: 0.968750, loss: 0.095150
train step #100/296 acc: 0.953125, loss: 0.175209
train step #150/296 acc: 0.968750, loss: 0.124589
train step #200/296 acc: 0.984375, loss: 0.063375
train step #250/296 acc: 0.968750, loss: 0.164717
Validation acc: 0.941201, loss: 0.182794
Test acc: 0.953125, loss: 0.150381
Cost time:150.943373s

Epoch: 10
train step #0/296 acc: 0.984375, loss: 0.078319
train step #50/296 acc: 0.984375, loss: 0.067316
train step #100/296 acc: 0.953125, loss: 0.153375
train step #150/296 acc: 0.968750, loss: 0.087253
train step #200/296 acc: 0.984375, loss: 0.057873
train step #250/296 acc: 0.968750, loss: 0.161850
Validation acc: 0.956826, loss: 0.149797
saving best model ...
Test acc: 0.959037, loss: 0.128380
Cost time:151.567917s

Epoch: 11
train step #0/296 acc: 0.984375, loss: 0.091170
train step #50/296 acc: 0.953125, loss: 0.104201
train step #100/296 acc: 0.953125, loss: 0.180357
train step #150/296 acc: 0.984375, loss: 0.059814
train step #200/296 acc: 0.984375, loss: 0.049300
train step #250/296 acc: 0.968750, loss: 0.166603
Validation acc: 0.944490, loss: 0.185702
Test acc: 0.950169, loss: 0.170242
Cost time:150.836963s

Epoch: 12
train step #0/296 acc: 0.984375, loss: 0.064433
train step #50/296 acc: 0.968750, loss: 0.098640
train step #100/296 acc: 0.968750, loss: 0.124657
train step #150/296 acc: 0.984375, loss: 0.056998
train step #200/296 acc: 0.968750, loss: 0.063977
train step #250/296 acc: 0.968750, loss: 0.140551
Validation acc: 0.943668, loss: 0.194250
Test acc: 0.951014, loss: 0.168849
Cost time:151.643665s

Epoch: 13
train step #0/296 acc: 0.968750, loss: 0.069528
train step #50/296 acc: 0.953125, loss: 0.109176
train step #100/296 acc: 0.937500, loss: 0.145082
train step #150/296 acc: 0.984375, loss: 0.066617
train step #200/296 acc: 1.000000, loss: 0.028011
train step #250/296 acc: 0.968750, loss: 0.150201
Validation acc: 0.948602, loss: 0.173358
Test acc: 0.953547, loss: 0.148226
Cost time:151.222108s

Epoch: 14
train step #0/296 acc: 0.968750, loss: 0.099347
train step #50/296 acc: 0.953125, loss: 0.119565
train step #100/296 acc: 0.953125, loss: 0.123260
train step #150/296 acc: 0.968750, loss: 0.077242
train step #200/296 acc: 0.984375, loss: 0.063655
train step #250/296 acc: 0.968750, loss: 0.141923
Validation acc: 0.947368, loss: 0.169933
Test acc: 0.959037, loss: 0.133765
Cost time:151.522387s

Epoch: 15
train step #0/296 acc: 0.984375, loss: 0.079798
train step #50/296 acc: 0.968750, loss: 0.073034
train step #100/296 acc: 0.984375, loss: 0.109261
train step #150/296 acc: 0.968750, loss: 0.068946
train step #200/296 acc: 1.000000, loss: 0.015726
train step #250/296 acc: 0.968750, loss: 0.143879
Validation acc: 0.953125, loss: 0.159744
Test acc: 0.954392, loss: 0.141515
Cost time:150.717850s

Test acc: 0.959037, loss: 0.128380
Best validation acc:0.956826
