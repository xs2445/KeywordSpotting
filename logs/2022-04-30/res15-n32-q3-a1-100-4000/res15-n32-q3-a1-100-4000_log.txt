Date: 2022-05-01 00:02:26.965770 

Model name: res15
Dataset: n32-q3-a1-100-4000
Input shape: (32, 100)
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 45, 32, 100]             405
            Conv2d-2          [-1, 45, 32, 100]          18,225
       BatchNorm2d-3          [-1, 45, 32, 100]               0
            Conv2d-4          [-1, 45, 32, 100]          18,225
       BatchNorm2d-5          [-1, 45, 32, 100]               0
            Conv2d-6          [-1, 45, 32, 100]          18,225
       BatchNorm2d-7          [-1, 45, 32, 100]               0
            Conv2d-8          [-1, 45, 32, 100]          18,225
       BatchNorm2d-9          [-1, 45, 32, 100]               0
           Conv2d-10          [-1, 45, 32, 100]          18,225
      BatchNorm2d-11          [-1, 45, 32, 100]               0
           Conv2d-12          [-1, 45, 32, 100]          18,225
      BatchNorm2d-13          [-1, 45, 32, 100]               0
           Conv2d-14          [-1, 45, 32, 100]          18,225
      BatchNorm2d-15          [-1, 45, 32, 100]               0
           Conv2d-16          [-1, 45, 32, 100]          18,225
      BatchNorm2d-17          [-1, 45, 32, 100]               0
           Conv2d-18          [-1, 45, 32, 100]          18,225
      BatchNorm2d-19          [-1, 45, 32, 100]               0
           Conv2d-20          [-1, 45, 32, 100]          18,225
      BatchNorm2d-21          [-1, 45, 32, 100]               0
           Conv2d-22          [-1, 45, 32, 100]          18,225
      BatchNorm2d-23          [-1, 45, 32, 100]               0
           Conv2d-24          [-1, 45, 32, 100]          18,225
      BatchNorm2d-25          [-1, 45, 32, 100]               0
           Conv2d-26          [-1, 45, 32, 100]          18,225
      BatchNorm2d-27          [-1, 45, 32, 100]               0
           Linear-28                   [-1, 10]             460
================================================================
Total params: 237,790
Trainable params: 237,790
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 29.66
Params size (MB): 0.91
Estimated Total Size (MB): 30.58
----------------------------------------------------------------
traning sample:18945
validation sample:2369
testing sample:2368

Using gpu: Tesla K80
Training epoches: 15
Training batches: 296

Epoch: 1
train step #0/296 acc: 0.062500, loss: 2.349739
train step #50/296 acc: 0.515625, loss: 1.350849
train step #100/296 acc: 0.593750, loss: 1.237537
train step #150/296 acc: 0.765625, loss: 0.787335
train step #200/296 acc: 0.875000, loss: 0.534917
train step #250/296 acc: 0.921875, loss: 0.452579
Validation acc: 0.796875, loss: 0.613840
saving best model ...
Test acc: 0.809966, loss: 0.614322
Cost time:511.434200s

Epoch: 2
train step #0/296 acc: 0.859375, loss: 0.395965
train step #50/296 acc: 0.906250, loss: 0.305871
train step #100/296 acc: 0.812500, loss: 0.616574
train step #150/296 acc: 0.859375, loss: 0.414866
train step #200/296 acc: 0.921875, loss: 0.298407
train step #250/296 acc: 0.859375, loss: 0.305515
Validation acc: 0.853207, loss: 0.436252
saving best model ...
Test acc: 0.864443, loss: 0.411330
Cost time:151.105316s

Epoch: 3
train step #0/296 acc: 0.953125, loss: 0.223561
train step #50/296 acc: 0.968750, loss: 0.212542
train step #100/296 acc: 0.875000, loss: 0.395720
train step #150/296 acc: 0.875000, loss: 0.333377
train step #200/296 acc: 0.906250, loss: 0.227577
train step #250/296 acc: 0.937500, loss: 0.210535
Validation acc: 0.872533, loss: 0.376931
saving best model ...
Test acc: 0.888091, loss: 0.334147
Cost time:151.167137s

Epoch: 4
train step #0/296 acc: 0.968750, loss: 0.127933
train step #50/296 acc: 0.937500, loss: 0.223220
train step #100/296 acc: 0.875000, loss: 0.370163
train step #150/296 acc: 0.890625, loss: 0.337337
train step #200/296 acc: 0.921875, loss: 0.193020
train step #250/296 acc: 0.984375, loss: 0.168053
Validation acc: 0.943257, loss: 0.216769
saving best model ...
Test acc: 0.936655, loss: 0.193722
Cost time:151.361546s

Epoch: 5
train step #0/296 acc: 0.984375, loss: 0.102633
train step #50/296 acc: 0.968750, loss: 0.124829
train step #100/296 acc: 0.875000, loss: 0.370708
train step #150/296 acc: 0.890625, loss: 0.277134
train step #200/296 acc: 0.968750, loss: 0.137610
train step #250/296 acc: 0.968750, loss: 0.136119
Validation acc: 0.907072, loss: 0.234177
Test acc: 0.931166, loss: 0.214478
Cost time:150.911547s

Epoch: 6
train step #0/296 acc: 0.984375, loss: 0.085921
train step #50/296 acc: 0.968750, loss: 0.095429
train step #100/296 acc: 0.906250, loss: 0.297584
train step #150/296 acc: 0.921875, loss: 0.221475
train step #200/296 acc: 0.968750, loss: 0.100790
train step #250/296 acc: 0.953125, loss: 0.193846
Validation acc: 0.912007, loss: 0.276075
Test acc: 0.929054, loss: 0.214274
Cost time:150.897410s

Epoch: 7
train step #0/296 acc: 0.984375, loss: 0.065661
train step #50/296 acc: 0.984375, loss: 0.077436
train step #100/296 acc: 0.890625, loss: 0.327411
train step #150/296 acc: 0.937500, loss: 0.224261
train step #200/296 acc: 0.968750, loss: 0.106555
train step #250/296 acc: 0.984375, loss: 0.135408
Validation acc: 0.923931, loss: 0.200319
Test acc: 0.945101, loss: 0.160998
Cost time:150.860017s

Epoch: 8
train step #0/296 acc: 0.984375, loss: 0.070860
train step #50/296 acc: 0.968750, loss: 0.096221
train step #100/296 acc: 0.890625, loss: 0.296172
train step #150/296 acc: 0.937500, loss: 0.200521
train step #200/296 acc: 0.968750, loss: 0.113462
train step #250/296 acc: 0.968750, loss: 0.124026
Validation acc: 0.956003, loss: 0.158578
saving best model ...
Test acc: 0.954392, loss: 0.140155
Cost time:151.360272s

Epoch: 9
train step #0/296 acc: 0.968750, loss: 0.081185
train step #50/296 acc: 0.953125, loss: 0.136706
train step #100/296 acc: 0.921875, loss: 0.253047
train step #150/296 acc: 0.921875, loss: 0.211396
train step #200/296 acc: 0.984375, loss: 0.097043
train step #250/296 acc: 0.984375, loss: 0.124077
Validation acc: 0.919819, loss: 0.241838
Test acc: 0.941301, loss: 0.171555
Cost time:151.738727s

Epoch: 10
train step #0/296 acc: 0.984375, loss: 0.072250
train step #50/296 acc: 0.968750, loss: 0.095423
train step #100/296 acc: 0.906250, loss: 0.258996
train step #150/296 acc: 0.937500, loss: 0.208631
train step #200/296 acc: 0.968750, loss: 0.095162
train step #250/296 acc: 0.953125, loss: 0.129602
Validation acc: 0.927632, loss: 0.177816
Test acc: 0.947635, loss: 0.152620
Cost time:150.984125s

Epoch: 11
train step #0/296 acc: 0.984375, loss: 0.061918
train step #50/296 acc: 0.984375, loss: 0.088376
train step #100/296 acc: 0.906250, loss: 0.257927
train step #150/296 acc: 0.921875, loss: 0.248023
train step #200/296 acc: 0.937500, loss: 0.118990
train step #250/296 acc: 0.984375, loss: 0.058352
Validation acc: 0.923109, loss: 0.252455
Test acc: 0.948480, loss: 0.167207
Cost time:151.032603s

Epoch: 12
train step #0/296 acc: 0.984375, loss: 0.044819
train step #50/296 acc: 0.984375, loss: 0.075998
train step #100/296 acc: 0.921875, loss: 0.207696
train step #150/296 acc: 0.953125, loss: 0.176886
train step #200/296 acc: 0.968750, loss: 0.078468
train step #250/296 acc: 0.984375, loss: 0.088519
Validation acc: 0.929276, loss: 0.237557
Test acc: 0.953970, loss: 0.144046
Cost time:150.808755s

Epoch: 13
train step #0/296 acc: 0.984375, loss: 0.033946
train step #50/296 acc: 0.984375, loss: 0.074794
train step #100/296 acc: 0.890625, loss: 0.270765
train step #150/296 acc: 0.953125, loss: 0.180719
train step #200/296 acc: 0.968750, loss: 0.083069
train step #250/296 acc: 1.000000, loss: 0.042033
Validation acc: 0.919819, loss: 0.272351
Test acc: 0.946791, loss: 0.182336
Cost time:151.381478s

Epoch: 14
train step #0/296 acc: 0.968750, loss: 0.054764
train step #50/296 acc: 0.968750, loss: 0.096399
train step #100/296 acc: 0.937500, loss: 0.183460
train step #150/296 acc: 0.937500, loss: 0.178637
train step #200/296 acc: 0.968750, loss: 0.076285
train step #250/296 acc: 1.000000, loss: 0.021074
Validation acc: 0.947368, loss: 0.208283
Test acc: 0.939189, loss: 0.203457
Cost time:150.887787s

Epoch: 15
train step #0/296 acc: 1.000000, loss: 0.028362
train step #50/296 acc: 0.984375, loss: 0.051114
train step #100/296 acc: 0.937500, loss: 0.202200
train step #150/296 acc: 0.937500, loss: 0.177039
train step #200/296 acc: 0.953125, loss: 0.111429
train step #250/296 acc: 1.000000, loss: 0.036783
Validation acc: 0.930510, loss: 0.217510
Test acc: 0.951014, loss: 0.149197
Cost time:151.494788s

Test acc: 0.954392, loss: 0.140155
Best validation acc:0.956003
