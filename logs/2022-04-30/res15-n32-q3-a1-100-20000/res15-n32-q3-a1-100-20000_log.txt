Date: 2022-05-01 05:41:59.539274 

Model name: res15
Dataset: n32-q3-a1-100-20000
Input shape: (32, 100)
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 45, 32, 100]             405
            Conv2d-2          [-1, 45, 32, 100]          18,225
       BatchNorm2d-3          [-1, 45, 32, 100]               0
            Conv2d-4          [-1, 45, 32, 100]          18,225
       BatchNorm2d-5          [-1, 45, 32, 100]               0
            Conv2d-6          [-1, 45, 32, 100]          18,225
       BatchNorm2d-7          [-1, 45, 32, 100]               0
            Conv2d-8          [-1, 45, 32, 100]          18,225
       BatchNorm2d-9          [-1, 45, 32, 100]               0
           Conv2d-10          [-1, 45, 32, 100]          18,225
      BatchNorm2d-11          [-1, 45, 32, 100]               0
           Conv2d-12          [-1, 45, 32, 100]          18,225
      BatchNorm2d-13          [-1, 45, 32, 100]               0
           Conv2d-14          [-1, 45, 32, 100]          18,225
      BatchNorm2d-15          [-1, 45, 32, 100]               0
           Conv2d-16          [-1, 45, 32, 100]          18,225
      BatchNorm2d-17          [-1, 45, 32, 100]               0
           Conv2d-18          [-1, 45, 32, 100]          18,225
      BatchNorm2d-19          [-1, 45, 32, 100]               0
           Conv2d-20          [-1, 45, 32, 100]          18,225
      BatchNorm2d-21          [-1, 45, 32, 100]               0
           Conv2d-22          [-1, 45, 32, 100]          18,225
      BatchNorm2d-23          [-1, 45, 32, 100]               0
           Conv2d-24          [-1, 45, 32, 100]          18,225
      BatchNorm2d-25          [-1, 45, 32, 100]               0
           Conv2d-26          [-1, 45, 32, 100]          18,225
      BatchNorm2d-27          [-1, 45, 32, 100]               0
           Linear-28                   [-1, 10]             460
================================================================
Total params: 237,790
Trainable params: 237,790
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 29.66
Params size (MB): 0.91
Estimated Total Size (MB): 30.58
----------------------------------------------------------------
traning sample:18945
validation sample:2369
testing sample:2368

Using gpu: Tesla K80
Training epoches: 15
Training batches: 296

Epoch: 1
train step #0/296 acc: 0.093750, loss: 2.325264
train step #50/296 acc: 0.468750, loss: 1.452059
train step #100/296 acc: 0.718750, loss: 0.877202
train step #150/296 acc: 0.843750, loss: 0.619635
train step #200/296 acc: 0.843750, loss: 0.462564
train step #250/296 acc: 0.921875, loss: 0.371769
Validation acc: 0.831826, loss: 0.544882
saving best model ...
Test acc: 0.825591, loss: 0.541275
Cost time:151.729155s

Epoch: 2
train step #0/296 acc: 0.859375, loss: 0.376181
train step #50/296 acc: 0.906250, loss: 0.337327
train step #100/296 acc: 0.953125, loss: 0.210659
train step #150/296 acc: 0.984375, loss: 0.183411
train step #200/296 acc: 0.937500, loss: 0.171974
train step #250/296 acc: 0.968750, loss: 0.157537
Validation acc: 0.836349, loss: 0.493549
saving best model ...
Test acc: 0.833615, loss: 0.507245
Cost time:151.037818s

Epoch: 3
train step #0/296 acc: 0.921875, loss: 0.252756
train step #50/296 acc: 0.953125, loss: 0.228677
train step #100/296 acc: 0.984375, loss: 0.141324
train step #150/296 acc: 0.984375, loss: 0.102294
train step #200/296 acc: 0.984375, loss: 0.102793
train step #250/296 acc: 0.968750, loss: 0.140938
Validation acc: 0.899671, loss: 0.322602
saving best model ...
Test acc: 0.900760, loss: 0.325446
Cost time:151.201553s

Epoch: 4
train step #0/296 acc: 0.953125, loss: 0.138815
train step #50/296 acc: 0.921875, loss: 0.239758
train step #100/296 acc: 0.984375, loss: 0.108466
train step #150/296 acc: 0.984375, loss: 0.094669
train step #200/296 acc: 0.984375, loss: 0.074135
train step #250/296 acc: 0.968750, loss: 0.112947
Validation acc: 0.935444, loss: 0.216391
saving best model ...
Test acc: 0.937078, loss: 0.198378
Cost time:151.287469s

Epoch: 5
train step #0/296 acc: 0.968750, loss: 0.112016
train step #50/296 acc: 0.953125, loss: 0.160187
train step #100/296 acc: 0.984375, loss: 0.103324
train step #150/296 acc: 0.984375, loss: 0.080899
train step #200/296 acc: 0.984375, loss: 0.053807
train step #250/296 acc: 0.984375, loss: 0.119441
Validation acc: 0.942845, loss: 0.185482
saving best model ...
Test acc: 0.942145, loss: 0.170041
Cost time:151.062255s

Epoch: 6
train step #0/296 acc: 0.968750, loss: 0.118404
train step #50/296 acc: 0.968750, loss: 0.149556
train step #100/296 acc: 0.984375, loss: 0.066025
train step #150/296 acc: 0.968750, loss: 0.074246
train step #200/296 acc: 1.000000, loss: 0.037326
train step #250/296 acc: 0.953125, loss: 0.147205
Validation acc: 0.951480, loss: 0.147683
saving best model ...
Test acc: 0.954814, loss: 0.135134
Cost time:151.578506s

Epoch: 7
train step #0/296 acc: 0.953125, loss: 0.096156
train step #50/296 acc: 0.968750, loss: 0.118123
train step #100/296 acc: 1.000000, loss: 0.059531
train step #150/296 acc: 1.000000, loss: 0.025057
train step #200/296 acc: 1.000000, loss: 0.026646
train step #250/296 acc: 0.984375, loss: 0.085049
Validation acc: 0.944079, loss: 0.184790
Test acc: 0.947635, loss: 0.159455
Cost time:150.861103s

Epoch: 8
train step #0/296 acc: 0.968750, loss: 0.091845
train step #50/296 acc: 0.968750, loss: 0.105174
train step #100/296 acc: 1.000000, loss: 0.045279
train step #150/296 acc: 0.984375, loss: 0.039834
train step #200/296 acc: 1.000000, loss: 0.020372
train step #250/296 acc: 1.000000, loss: 0.045178
Validation acc: 0.951480, loss: 0.145220
saving best model ...
Test acc: 0.958193, loss: 0.125721
Cost time:151.435191s

Epoch: 9
train step #0/296 acc: 0.953125, loss: 0.101899
train step #50/296 acc: 0.968750, loss: 0.105944
train step #100/296 acc: 1.000000, loss: 0.026131
train step #150/296 acc: 1.000000, loss: 0.021491
train step #200/296 acc: 1.000000, loss: 0.009209
train step #250/296 acc: 1.000000, loss: 0.049604
Validation acc: 0.945312, loss: 0.163302
Test acc: 0.953970, loss: 0.143049
Cost time:151.004379s

Epoch: 10
train step #0/296 acc: 0.984375, loss: 0.084379
train step #50/296 acc: 0.968750, loss: 0.111238
train step #100/296 acc: 0.984375, loss: 0.053390
train step #150/296 acc: 0.984375, loss: 0.023081
train step #200/296 acc: 0.984375, loss: 0.035069
train step #250/296 acc: 0.984375, loss: 0.057274
Validation acc: 0.955181, loss: 0.150926
saving best model ...
Test acc: 0.952280, loss: 0.146046
Cost time:151.276271s

Epoch: 11
train step #0/296 acc: 0.984375, loss: 0.057670
train step #50/296 acc: 0.968750, loss: 0.086789
train step #100/296 acc: 1.000000, loss: 0.021190
train step #150/296 acc: 1.000000, loss: 0.032517
train step #200/296 acc: 1.000000, loss: 0.011012
train step #250/296 acc: 0.984375, loss: 0.061171
Validation acc: 0.951891, loss: 0.157138
Test acc: 0.954814, loss: 0.138078
Cost time:150.560826s

Epoch: 12
train step #0/296 acc: 1.000000, loss: 0.034502
train step #50/296 acc: 0.968750, loss: 0.100688
train step #100/296 acc: 1.000000, loss: 0.018495
train step #150/296 acc: 1.000000, loss: 0.017573
train step #200/296 acc: 1.000000, loss: 0.018493
train step #250/296 acc: 0.984375, loss: 0.055827
Validation acc: 0.958882, loss: 0.138919
saving best model ...
Test acc: 0.960304, loss: 0.125615
Cost time:151.320789s

Epoch: 13
train step #0/296 acc: 1.000000, loss: 0.036103
train step #50/296 acc: 0.953125, loss: 0.108622
train step #100/296 acc: 1.000000, loss: 0.015572
train step #150/296 acc: 1.000000, loss: 0.022563
train step #200/296 acc: 0.984375, loss: 0.019289
train step #250/296 acc: 1.000000, loss: 0.045091
Validation acc: 0.949836, loss: 0.154221
Test acc: 0.962416, loss: 0.137581
Cost time:150.864573s

Epoch: 14
train step #0/296 acc: 1.000000, loss: 0.016091
train step #50/296 acc: 0.968750, loss: 0.102482
train step #100/296 acc: 0.984375, loss: 0.023993
train step #150/296 acc: 1.000000, loss: 0.017259
train step #200/296 acc: 1.000000, loss: 0.011701
train step #250/296 acc: 0.984375, loss: 0.052549
Validation acc: 0.951069, loss: 0.167745
Test acc: 0.953970, loss: 0.162823
Cost time:151.311024s

Epoch: 15
train step #0/296 acc: 1.000000, loss: 0.024403
train step #50/296 acc: 0.953125, loss: 0.145254
train step #100/296 acc: 0.984375, loss: 0.080173
train step #150/296 acc: 1.000000, loss: 0.013268
train step #200/296 acc: 0.984375, loss: 0.069139
train step #250/296 acc: 1.000000, loss: 0.035444
Validation acc: 0.950658, loss: 0.164928
Test acc: 0.959037, loss: 0.146767
Cost time:151.159838s

Test acc: 0.960304, loss: 0.125615
Best validation acc:0.958882
