Date: 2022-05-01 00:46:21.136213 

Model name: res15
Dataset: n32-q3-a1-100-5000
Input shape: (32, 100)
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 45, 32, 100]             405
            Conv2d-2          [-1, 45, 32, 100]          18,225
       BatchNorm2d-3          [-1, 45, 32, 100]               0
            Conv2d-4          [-1, 45, 32, 100]          18,225
       BatchNorm2d-5          [-1, 45, 32, 100]               0
            Conv2d-6          [-1, 45, 32, 100]          18,225
       BatchNorm2d-7          [-1, 45, 32, 100]               0
            Conv2d-8          [-1, 45, 32, 100]          18,225
       BatchNorm2d-9          [-1, 45, 32, 100]               0
           Conv2d-10          [-1, 45, 32, 100]          18,225
      BatchNorm2d-11          [-1, 45, 32, 100]               0
           Conv2d-12          [-1, 45, 32, 100]          18,225
      BatchNorm2d-13          [-1, 45, 32, 100]               0
           Conv2d-14          [-1, 45, 32, 100]          18,225
      BatchNorm2d-15          [-1, 45, 32, 100]               0
           Conv2d-16          [-1, 45, 32, 100]          18,225
      BatchNorm2d-17          [-1, 45, 32, 100]               0
           Conv2d-18          [-1, 45, 32, 100]          18,225
      BatchNorm2d-19          [-1, 45, 32, 100]               0
           Conv2d-20          [-1, 45, 32, 100]          18,225
      BatchNorm2d-21          [-1, 45, 32, 100]               0
           Conv2d-22          [-1, 45, 32, 100]          18,225
      BatchNorm2d-23          [-1, 45, 32, 100]               0
           Conv2d-24          [-1, 45, 32, 100]          18,225
      BatchNorm2d-25          [-1, 45, 32, 100]               0
           Conv2d-26          [-1, 45, 32, 100]          18,225
      BatchNorm2d-27          [-1, 45, 32, 100]               0
           Linear-28                   [-1, 10]             460
================================================================
Total params: 237,790
Trainable params: 237,790
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 29.66
Params size (MB): 0.91
Estimated Total Size (MB): 30.58
----------------------------------------------------------------
traning sample:18945
validation sample:2369
testing sample:2368

Using gpu: Tesla K80
Training epoches: 15
Training batches: 296

Epoch: 1
train step #0/296 acc: 0.156250, loss: 2.318465
train step #50/296 acc: 0.687500, loss: 1.287068
train step #100/296 acc: 0.718750, loss: 0.905396
train step #150/296 acc: 0.765625, loss: 0.699742
train step #200/296 acc: 0.859375, loss: 0.451789
train step #250/296 acc: 0.812500, loss: 0.600012
Validation acc: 0.888980, loss: 0.422035
saving best model ...
Test acc: 0.894426, loss: 0.408980
Cost time:528.926470s

Epoch: 2
train step #0/296 acc: 0.875000, loss: 0.415056
train step #50/296 acc: 0.890625, loss: 0.289401
train step #100/296 acc: 0.890625, loss: 0.314732
train step #150/296 acc: 0.906250, loss: 0.255499
train step #200/296 acc: 0.937500, loss: 0.239674
train step #250/296 acc: 0.921875, loss: 0.316171
Validation acc: 0.905428, loss: 0.299151
saving best model ...
Test acc: 0.910473, loss: 0.279502
Cost time:150.718602s

Epoch: 3
train step #0/296 acc: 0.906250, loss: 0.302982
train step #50/296 acc: 0.937500, loss: 0.208421
train step #100/296 acc: 0.968750, loss: 0.132072
train step #150/296 acc: 0.937500, loss: 0.183371
train step #200/296 acc: 0.968750, loss: 0.149321
train step #250/296 acc: 0.937500, loss: 0.212869
Validation acc: 0.921464, loss: 0.241402
saving best model ...
Test acc: 0.929476, loss: 0.221235
Cost time:151.159265s

Epoch: 4
train step #0/296 acc: 0.937500, loss: 0.217587
train step #50/296 acc: 0.921875, loss: 0.170175
train step #100/296 acc: 0.968750, loss: 0.112602
train step #150/296 acc: 0.937500, loss: 0.182910
train step #200/296 acc: 0.968750, loss: 0.093552
train step #250/296 acc: 0.953125, loss: 0.194496
Validation acc: 0.913651, loss: 0.242920
Test acc: 0.926943, loss: 0.220824
Cost time:150.642251s

Epoch: 5
train step #0/296 acc: 0.937500, loss: 0.199762
train step #50/296 acc: 0.984375, loss: 0.114449
train step #100/296 acc: 0.953125, loss: 0.130984
train step #150/296 acc: 0.968750, loss: 0.129837
train step #200/296 acc: 0.984375, loss: 0.067357
train step #250/296 acc: 0.968750, loss: 0.163923
Validation acc: 0.933799, loss: 0.193257
saving best model ...
Test acc: 0.940034, loss: 0.181669
Cost time:151.064327s

Epoch: 6
train step #0/296 acc: 0.937500, loss: 0.161240
train step #50/296 acc: 0.953125, loss: 0.118235
train step #100/296 acc: 0.953125, loss: 0.092922
train step #150/296 acc: 0.953125, loss: 0.146367
train step #200/296 acc: 0.984375, loss: 0.060735
train step #250/296 acc: 0.937500, loss: 0.160776
Validation acc: 0.929688, loss: 0.209308
Test acc: 0.929476, loss: 0.218701
Cost time:150.897694s

Epoch: 7
train step #0/296 acc: 0.968750, loss: 0.142547
train step #50/296 acc: 0.968750, loss: 0.087290
train step #100/296 acc: 0.937500, loss: 0.157506
train step #150/296 acc: 0.953125, loss: 0.163761
train step #200/296 acc: 0.984375, loss: 0.056324
train step #250/296 acc: 0.937500, loss: 0.146258
Validation acc: 0.928454, loss: 0.205229
Test acc: 0.934122, loss: 0.204307
Cost time:151.223613s

Epoch: 8
train step #0/296 acc: 0.968750, loss: 0.098661
train step #50/296 acc: 0.984375, loss: 0.038665
train step #100/296 acc: 0.953125, loss: 0.074883
train step #150/296 acc: 0.937500, loss: 0.134417
train step #200/296 acc: 0.984375, loss: 0.052251
train step #250/296 acc: 0.921875, loss: 0.156318
Validation acc: 0.917352, loss: 0.249084
Test acc: 0.923564, loss: 0.241177
Cost time:150.949379s

Epoch: 9
train step #0/296 acc: 0.953125, loss: 0.108318
train step #50/296 acc: 1.000000, loss: 0.025800
train step #100/296 acc: 0.953125, loss: 0.113409
train step #150/296 acc: 0.937500, loss: 0.164676
train step #200/296 acc: 0.984375, loss: 0.054465
train step #250/296 acc: 0.937500, loss: 0.139918
Validation acc: 0.930510, loss: 0.216477
Test acc: 0.939611, loss: 0.195030
Cost time:151.133949s

Epoch: 10
train step #0/296 acc: 0.968750, loss: 0.068968
train step #50/296 acc: 0.984375, loss: 0.048172
train step #100/296 acc: 1.000000, loss: 0.044815
train step #150/296 acc: 0.984375, loss: 0.089809
train step #200/296 acc: 0.984375, loss: 0.055378
train step #250/296 acc: 0.953125, loss: 0.119871
Validation acc: 0.933799, loss: 0.219123
saving best model ...
Test acc: 0.932432, loss: 0.225085
Cost time:150.676361s

Epoch: 11
train step #0/296 acc: 0.968750, loss: 0.077108
train step #50/296 acc: 1.000000, loss: 0.036046
train step #100/296 acc: 0.968750, loss: 0.073943
train step #150/296 acc: 0.968750, loss: 0.085872
train step #200/296 acc: 0.984375, loss: 0.052968
train step #250/296 acc: 0.953125, loss: 0.120455
Validation acc: 0.928865, loss: 0.212387
Test acc: 0.930743, loss: 0.211544
Cost time:151.098772s

Epoch: 12
train step #0/296 acc: 0.968750, loss: 0.087911
train step #50/296 acc: 1.000000, loss: 0.024430
train step #100/296 acc: 0.968750, loss: 0.053913
train step #150/296 acc: 0.984375, loss: 0.040980
train step #200/296 acc: 0.984375, loss: 0.056649
train step #250/296 acc: 0.953125, loss: 0.124556
Validation acc: 0.950658, loss: 0.156920
saving best model ...
Test acc: 0.950591, loss: 0.149995
Cost time:150.978999s

Epoch: 13
train step #0/296 acc: 1.000000, loss: 0.036059
train step #50/296 acc: 1.000000, loss: 0.011116
train step #100/296 acc: 1.000000, loss: 0.014023
train step #150/296 acc: 0.984375, loss: 0.034981
train step #200/296 acc: 0.984375, loss: 0.040187
train step #250/296 acc: 0.921875, loss: 0.151959
Validation acc: 0.944079, loss: 0.174135
Test acc: 0.947213, loss: 0.173377
Cost time:151.096085s

Epoch: 14
train step #0/296 acc: 1.000000, loss: 0.057788
train step #50/296 acc: 1.000000, loss: 0.018778
train step #100/296 acc: 1.000000, loss: 0.032439
train step #150/296 acc: 0.984375, loss: 0.044190
train step #200/296 acc: 0.984375, loss: 0.044089
train step #250/296 acc: 0.968750, loss: 0.108737
Validation acc: 0.942023, loss: 0.187774
Test acc: 0.938767, loss: 0.199943
Cost time:150.591145s

Epoch: 15
train step #0/296 acc: 1.000000, loss: 0.025943
train step #50/296 acc: 0.984375, loss: 0.021638
train step #100/296 acc: 0.984375, loss: 0.039058
train step #150/296 acc: 1.000000, loss: 0.012426
train step #200/296 acc: 0.984375, loss: 0.042472
train step #250/296 acc: 0.937500, loss: 0.129878
Validation acc: 0.946546, loss: 0.164243
Test acc: 0.944679, loss: 0.170874
Cost time:150.636606s

Test acc: 0.950591, loss: 0.149995
Best validation acc:0.950658
